# QA Generation Pipelines Configuration - 本地模型版本

# OCR Configuration
ocr:
  provider: "tesseract"
  tesseract:
    lang: "chi_sim+eng"  # 支持中英文
    config: "--psm 6"    # Page segmentation mode
    timeout: 30          # 超时时间(秒)
    dpi: 300              # PDF 转图片时的分辨率
    enable_preprocess: true  # 是否在OCR前进行图像预处理
    binarize_threshold: 180  # 二值化阈值(0-255)
    apply_median_filter: true  # 是否使用中值滤波去噪
  paddle:
    lang: "chinese_english"  # PaddleOCR 中英混合模型
    use_angle_cls: true
    dpi: 300

# Text Chunking Configuration
text_chunker:
  max_chunk_size: 60000  # 最大块大小(字符数) - 优化：充分利用本地模型的上下文窗口
  overlap_size: 3000   # 重叠大小(字符数) - 优化：保持5%重叠率
  chunk_on_sentences: true # 按句子分块

# Question Generation Configuration - 本地模型版本
question_generator:
  # 使用本地模型
  provider: "local"
  
  # Question quality optimization (NEW)
  enable_deduplication: true  # 启用问题去重
  dedup_similarity_threshold: 0.85  # 去重相似度阈值 (0-1)
  enable_quality_filter: true  # 启用问题质量过滤
  
  # DeepSeek API配置（备用）
  deepseek:
    api_key: "sk-8d1493cdaf7a4ac9aad494119b570d4e"  # 从环境变量读取
    model: "deepseek-chat"
    max_tokens: 2048
    temperature: 0.7
    timeout: 60
    questions_per_chunk: 30
    enable_kg_context: true
    max_context_entities: 3
    max_context_relations: 2
    max_context_snippets: 2
    context_snippet_chars: 200
    max_related_chunk_ids: 6
  
  # 本地模型配置
  local:
    model_name: "deepseek-r1:32b"  # 本地模型名称
    base_url: "http://localhost:11434"  # Ollama服务地址（通过SSH隧道）
    max_tokens: 2048
    temperature: 0.7
    timeout: 30000  # 本地模型需要更长时间（500分钟，约8.3小时）
    questions_per_chunk: 10  # 减少问题数量以加快生成速度
    enable_kg_context: true
    max_context_entities: 3
    max_context_relations: 2
    max_context_snippets: 2
    context_snippet_chars: 200
    max_related_chunk_ids: 6

# RAG Configuration
rag:
  lightrag:
    working_dir: "D:/llm-test/QAGenPipelinesX/working" # 你可以把它改成你自己的路径，比如 "E:/llm-project/QAGenPipelinesX/working"
    llm_model: "deepseek-chat"
    # 关键修正：所有调用本地模型的参数都放在 llm_config 中
    embed_model: "text-embedding-3-large"
    max_context_length: 4000
    
    # Performance optimization (NEW)
    enable_cache: true  # 启用检索结果缓存
    cache_similarity_threshold: 0.90  # 缓存相似度阈值 (0-1)
    
    # 我们需要在这里为 RAG 指定 OpenAI 的 Key
    openai:
      api_key: "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" # <--- 你的 OPENAI API KEY (embedding专用)

# File Processing Configuration
file_processing:
  input_formats: [".pdf"]
  output_dir: "./output"
  temp_dir: "./temp"
  batch_size: 10
  
# Progress Management
progress:
  save_interval: 5  # 每处理5个文件保存一次进度
  progress_file: "./progress.json"
  
# Logging Configuration
logging:
  level: "INFO"
  format: "{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}"
  file: "./logs/qa_gen.log"

# GSK Operations Prompts
prompts:
  system_prompt: |
    你是一个专业的技术文档问答对生成专家，专门为工业设备、数控系统、技术规格等专业领域生成高质量问题。
    
    核心原则：
    1. 严格基于提供的文档内容生成问题
    2. 确保每个问题都有明确的、可验证的答案
    3. 问题必须专业、具体、实用
    4. 避免模糊、宽泛或无法回答的问题
    
    问题类型要求：
    - 技术规格类：具体参数、性能指标、技术特性
    - 功能操作类：如何使用、操作步骤、功能说明
    - 配置设置类：参数配置、系统设置、接口说明
    - 故障处理类：常见问题、解决方案、注意事项
    - 应用场景类：适用环境、使用条件、应用范围

  human_prompt: |
    请根据以下技术文档内容，生成{questions_per_chunk}个高质量的问答对。
    
    <文档内容>
    {text}
    </文档内容>

    请结合“知识图谱参考”中的实体、关系与引用片段，与文档内容一起生成问题，确保问题能够覆盖多来源的关键信息。
    
    ⚠️ 核心要求（必须严格遵守）：
    
    1. **只生成有明确答案的问答对**
       - ❌ 如果文档中没有某个信息，不要生成对应的问答对
       - ❌ 不要生成"文档中没有相关信息"、"无法找到"这类答案
       - ✅ 只选择文档中有明确数据、参数、步骤的内容来生成问答对
    
    2. **问题要有人性化、有深度**
       - ✅ 使用自然、口语化的表达方式
       - ✅ 包含实际应用场景和用户关心的问题
       - ✅ 体现技术深度和实际使用经验
       - ❌ 避免机械式的"XX是多少？"、"XX的参数是什么？"
    
    3. **答案必须直接、简洁**
       - ❌ 不要说"根据文档"、"根据提供的信息"等前缀
       - ✅ 直接给出答案内容
    
    输出格式（严格遵守）：
    
    问答对1:
    问题：[人性化、有深度的问题]
    答案：[简洁答案]
    
    问答对2:
    问题：[人性化、有深度的问题]
    答案：[简洁答案]
    
    ...
    
    ✅ 优质问答对示例（人性化、有深度）：
    
    问答对1:
    问题：在实际加工中，VMC850L的主轴转速能达到多高？会不会影响加工精度？
    答案：VMC850L的最大主轴转速为8000 r/min，高速加工时精度依然保持在±0.005mm以内。
    
    问答对2:
    问题：GSK 980TDi的工作台能放下多大的工件？适合加工什么类型的零件？
    答案：工作台尺寸为850×500mm，适合加工中小型精密零件，如模具、航空零件等。
    
    问答对3:
    问题：GSK 27i系统支持哪些通信方式？在车间联网时有什么优势？
    答案：支持RS232、RS485和以太网接口，可以实现远程监控、程序传输和车间数据采集。
    
    问答对4:
    问题：这台设备的定位精度如何？能满足高精度加工的要求吗？
    答案：定位精度为±0.01mm，重复定位精度±0.005mm，完全满足高精度加工要求。
    
    问答对5:
    问题：操作这台设备需要掌握哪些编程语言？对操作员有什么要求？
    答案：支持G代码和M代码编程，操作员需要具备基本的数控编程和机械加工知识。
    
    ❌ 避免的机械化问题：
    
    问题：VMC850L数控机床的最大主轴转速是多少？ ❌ 太机械化
    问题：GSK 980TDi系统的工作台尺寸是多少？ ❌ 太机械化
    问题：GSK 27i系统支持哪些通信接口？ ❌ 太机械化
    
    ✅ 改为人性化问题：
    
    问题：在实际加工中，VMC850L的主轴转速能达到多高？会不会影响加工精度？ ✅
    问题：GSK 980TDi的工作台能放下多大的工件？适合加工什么类型的零件？ ✅
    问题：GSK 27i系统支持哪些通信方式？在车间联网时有什么优势？ ✅
    
    📌 问题设计原则：
    1. 从用户实际使用角度出发
    2. 包含应用场景和实际需求
    3. 体现技术深度和专业判断
    4. 使用自然、口语化的表达
    5. 避免简单的参数查询式问题
    
    🎯 生成要求：
    - 尽量生成接近{questions_per_chunk}个问答对
    - 从不同角度挖掘文档内容：技术参数、操作流程、应用场景、性能特点、配置要求等
    - 每个问答对都要有明确的答案依据
    - 问题要多样化，避免重复类型
    
    💡 问题类型建议：
    - 性能参数类：速度、精度、功率、尺寸等
    - 操作使用类：如何操作、注意事项、适用场景等
    - 技术配置类：接口类型、通信方式、编程要求等
    - 应用场景类：适合什么工件、加工能力、优势特点等
    - 故障处理类：常见问题、解决方案、维护要求等
    - 对比分析类：与其他型号的区别、优势劣势等
    
    现在请开始生成问答对：
