"""Answer generation service."""

import logging
import re
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
from enum import Enum
import json
import asyncio

from ..interfaces.rag_interface import RAGInterface, RAGError
from ..interfaces.markdown_processor_interface import MarkdownProcessorInterface
from ..models.document import Document
from ..models.question import Question, QuestionSet
from ..models.qa_pair import QAPair, QASet
from ..utils.file_utils import FileUtils
from ..utils.path_utils import PathUtils
from ..utils.thread_event_loop import get_or_create_event_loop
from .progress_manager import ProgressManager


class AnswerType(Enum):
    """Answer type classification."""
    VALID_POSITIVE = "valid_positive"      # æœ‰æ•ˆçš„æ­£é¢ç­”æ¡ˆ
    VALID_NEGATIVE = "valid_negative"      # æœ‰æ•ˆçš„å¦å®šç­”æ¡ˆ ("ä¸æ”¯æŒXXåŠŸèƒ½")
    INVALID_NO_INFO = "invalid_no_info"    # æ— æ•ˆ("æ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯")
    INVALID_ERROR = "invalid_error"        # é”™è¯¯ä¿¡æ¯


class AnswerService:
    """Service for generating answers using RAG."""

    def __init__(
            self,
            rag: RAGInterface,
            markdown_processor: MarkdownProcessorInterface,
            progress_manager: ProgressManager,
            logger: Optional[logging.Logger] = None
    ):
        """
        Initialize the answer service.
        
        Args:
            rag: RAG implementation for answer generation
            markdown_processor: Markdown processor for cleaning answers
            progress_manager: Progress manager for tracking operations
            logger: Optional logger instance
        """
        self.rag = rag
        self.markdown_processor = markdown_processor
        self.progress_manager = progress_manager
        self.logger = logger or logging.getLogger(__name__)

    def setup_knowledge_base(self, documents_path: Path, working_dir: Optional[Path] = None) -> None:
        """
        Setup the knowledge base with documents.
        
        Args:
            documents_path: Path to directory containing processed documents
            working_dir: Working directory for the knowledge base
            
        Raises:
            AnswerServiceError: If setup fails
        """
        try:
            # ä½¿ç”¨æ–°çš„è·¯å¾„å·¥å…·æ ‡å‡†åŒ–è·¯å¾„
            normalized_documents_path = PathUtils.normalize_path(documents_path)
            safe_path_str = PathUtils.safe_path_string(normalized_documents_path)

            self.logger.info(f"Setting up knowledge base from: {safe_path_str}")

            if working_dir:
                normalized_working_dir = PathUtils.normalize_path(working_dir)
                # Check if working directory exists and has data
                if normalized_working_dir.exists() and any(normalized_working_dir.glob("*.json")):
                    # Working directory exists with data - append to existing KB
                    self.logger.info(f"Appending to existing knowledge base: {PathUtils.safe_path_string(normalized_working_dir)}")
                    self.rag.use_existing_knowledge_base(normalized_working_dir)
                else:
                    # Working directory doesn't exist or is empty - create new KB
                    self.logger.info(f"Creating new knowledge base: {PathUtils.safe_path_string(normalized_working_dir)}")
                    self.rag.set_working_directory(normalized_working_dir)
            else:
                # No working directory specified - clear default KB
                self.logger.info("Using default working directory with clean KB")
                self.rag.clear_knowledge_base()

            # éªŒè¯æ–‡æ¡£è·¯å¾„
            is_valid, error_msg = PathUtils.validate_path(
                normalized_documents_path,
                require_exists=True
            )

            if not is_valid:
                raise AnswerServiceError(f"Invalid documents path: {error_msg}")

            # Load documents from directory
            if normalized_documents_path.is_file() and normalized_documents_path.suffix == '.txt':
                # Single document
                document = self._load_document_from_file(normalized_documents_path)
                self.rag.insert_document(document)
            elif normalized_documents_path.is_dir():
                # Directory of documents
                documents = self._load_documents_from_directory(normalized_documents_path)
                if documents:
                    self.rag.insert_documents_batch(documents)
                else:
                    raise AnswerServiceError(f"No valid documents found in {safe_path_str}")
            else:
                raise AnswerServiceError(f"Invalid documents path: {safe_path_str} (not a .txt file or directory)")

            # Get knowledge base stats
            stats = self.rag.get_knowledge_base_stats()
            self.logger.info(f"Knowledge base setup complete: {stats}")

        except AnswerServiceError:
            # é‡æ–°æŠ›å‡ºå·²ç»æ ¼å¼åŒ–çš„é”™è¯¯
            raise
        except Exception as e:
            error_msg = f"Failed to setup knowledge base: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e

    def generate_answers_for_questions(
            self,
            questions_file: Path,
            output_file: Path,
            session_id: Optional[str] = None,
            resume: bool = True
    ) -> QASet:
        """
        Generate answers for questions from a file.
        
        Args:
            questions_file: Path to questions JSONL file
            output_file: Path to output QA pairs JSONL file
            session_id: Optional session ID for progress tracking
            resume: Whether to resume from previous session
            
        Returns:
            QASet: Generated QA pairs
            
        Raises:
            AnswerServiceError: If generation fails
        """
        try:
            self.logger.info(f"Generating answers for questions file: {questions_file}")
            
            # Load questions
            all_questions = self._load_questions_from_file(questions_file)
            if not all_questions:
                raise AnswerServiceError(f"No questions found in file: {questions_file}")
            
            self.logger.info(f"Loaded {len(all_questions)} questions from {questions_file}")
            
            # Create or resume session
            if not session_id:
                session_id = f"answer_gen_{questions_file.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Check for existing progress
            existing_qa_pairs = []
            if resume and output_file.exists():
                existing_qa_pairs = self._load_existing_qa_pairs(output_file)
                self.logger.info(f"Loaded {len(existing_qa_pairs)} existing QA pairs")
            
            # Filter out already answered questions
            questions_to_process = self._filter_unanswered_questions(all_questions, existing_qa_pairs)
            self.logger.info(f"Processing {len(questions_to_process)} remaining questions")
            
            # Start or update session
            if not resume or not existing_qa_pairs:
                # New session
                self.progress_manager.start_session(
                    session_id=session_id,
                    total_items=len(all_questions),
                    operation_type="answer_generation"
                )

            # Update progress for existing pairs
            if existing_qa_pairs:
                self.progress_manager.update_progress(session_id, len(existing_qa_pairs))

            # Generate answers for remaining questions
            if questions_to_process:
                self.logger.info(f"å¼€å§‹ç”Ÿæˆç­”æ¡ˆ: {len(questions_to_process)}ä¸ªé—®é¢˜")
                new_qa_set = self._generate_answers_batch(questions_to_process, session_id, output_file)
                new_qa_pairs = new_qa_set.qa_pairs
                self.logger.info(f"ç­”æ¡ˆç”Ÿæˆå®Œæˆ: {len(new_qa_pairs)}ä¸ªç­”æ¡ˆ")
            else:
                new_qa_pairs = []

            # Combine existing and new QA pairs
            all_qa_pairs = existing_qa_pairs + new_qa_pairs

            # Create final QA set
            qa_set = QASet(
                document_id=session_id,
                qa_pairs=all_qa_pairs,
                created_at=datetime.now()
            )

            # Save final results
            if not resume or new_qa_pairs:  # Only save if not resuming or if we have new pairs
                self._save_qa_set(qa_set, output_file)

            # Complete session
            self.progress_manager.complete_session(session_id)

            self.logger.info(f"Answer generation completed: {len(qa_set.qa_pairs)} total QA pairs "
                             f"({len(existing_qa_pairs)} existing + {len(new_qa_pairs)} new)")
            return qa_set

        except Exception as e:
            if session_id:
                self.progress_manager.fail_session(session_id, str(e))
            error_msg = f"Failed to generate answers: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e

    def generate_answers_for_directory(
            self,
            questions_dir: Path,
            output_dir: Path,
            session_id: Optional[str] = None
    ) -> Dict[str, QASet]:
        """
        Generate answers for all question files in a directory.
        
        Args:
            questions_dir: Directory containing question JSONL files
            output_dir: Directory for output QA JSONL files
            session_id: Optional session ID for progress tracking
            
        Returns:
            Dictionary mapping file names to QASet objects
            
        Raises:
            AnswerServiceError: If batch processing fails
        """
        try:
            # Create session if not provided
            if session_id is None:
                session_id = f"answer_batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            self.logger.info(f"Starting batch answer generation: {session_id}")

            # Find question files
            question_files = list(questions_dir.glob("*questions.jsonl"))
            if not question_files:
                raise AnswerServiceError(f"No question files found in {questions_dir}")

            # Create output directory
            output_dir.mkdir(parents=True, exist_ok=True)

            # Initialize progress
            self.progress_manager.start_session(
                session_id=session_id,
                total_items=len(question_files),
                operation_type="batch_answer_generation"
            )

            results = {}

            for question_file in question_files:
                try:
                    # Generate output filename
                    base_name = question_file.stem.replace("_questions", "")
                    output_file = output_dir / f"{base_name}_qa.jsonl"

                    # Generate answers
                    qa_set = self.generate_answers_for_questions(
                        question_file, output_file, f"{session_id}_{base_name}"
                    )

                    results[question_file.name] = qa_set

                    # Update progress
                    self.progress_manager.update_progress(session_id, 1)

                except Exception as e:
                    self.logger.error(f"Failed to process {question_file}: {str(e)}")
                    self.progress_manager.add_error(session_id, f"{question_file.name}: {str(e)}")
                    continue

            # Complete session
            self.progress_manager.complete_session(session_id)

            self.logger.info(f"Batch answer generation completed: {len(results)} files processed")
            return results

        except Exception as e:
            if session_id:
                self.progress_manager.fail_session(session_id, str(e))
            error_msg = f"Failed to process directory: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e

    def resume_answer_generation(self, session_id: str) -> Optional[QASet]:
        """
        Resume a failed answer generation session.
        
        Args:
            session_id: Session ID to resume
            
        Returns:
            QASet if resumption successful, None otherwise
            
        Raises:
            AnswerServiceError: If resumption fails
        """
        try:
            session = self.progress_manager.get_session(session_id)
            if not session:
                raise AnswerServiceError(f"Session not found: {session_id}")

            if session.status == "completed":
                self.logger.info(f"Session {session_id} already completed")
                return None

            self.logger.info(f"Resuming answer generation session: {session_id}")

            # Resume logic would depend on how we store intermediate results
            # For now, we'll just log that resumption is not implemented
            self.logger.warning("Answer generation resumption not yet implemented")
            return None

        except Exception as e:
            error_msg = f"Failed to resume session {session_id}: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e

    def get_knowledge_base_info(self) -> Dict[str, Any]:
        """
        Get information about the current knowledge base.
        
        Returns:
            Dictionary containing knowledge base information
        """
        try:
            return self.rag.get_knowledge_base_stats()
        except Exception as e:
            self.logger.error(f"Failed to get knowledge base info: {str(e)}")
            return {"error": str(e)}

    def _load_document_from_file(self, file_path: Path) -> Document:
        """Load a single document from file."""
        content = file_path.read_text(encoding='utf-8')
        return Document(
            file_path=file_path,
            content=content,
            file_type=file_path.suffix,
            file_size=len(content),
            created_at=datetime.fromtimestamp(file_path.stat().st_ctime),
            processed_at=datetime.now()
        )

    def _load_documents_from_directory(self, directory_path: Path) -> List[Document]:
        """Load all documents from a directory."""
        documents = []

        for file_path in directory_path.glob("*.txt"):
            try:
                document = self._load_document_from_file(file_path)
                documents.append(document)
            except Exception as e:
                self.logger.warning(f"Failed to load document {file_path}: {str(e)}")
                continue

        return documents

    def _load_questions_from_file(self, questions_file: Path) -> List[Question]:
        """Load questions from JSONL file (supports both single-line and multi-line formats)."""
        try:
            try:
                data = FileUtils.load_jsonl(questions_file)
            except Exception:
                # å…¼å®¹æ—§çš„â€œå¤šè¡Œ JSONï¼ˆæ¯ä¸ªå¯¹è±¡è¢« json.dump(indent=2) å†™å‡ºï¼‰â€æ ¼å¼ï¼š
                # è¿™ç§æ–‡ä»¶æ— æ³•ç”¨æ ‡å‡† jsonlines é€è¡Œè§£æï¼Œè¿™é‡ŒæŒ‰ç©ºè¡Œåˆ†å—å›é€€è§£æã€‚
                raw = questions_file.read_text(encoding="utf-8")
                blocks = [b.strip() for b in raw.split("\n\n") if b.strip()]
                data = [json.loads(b) for b in blocks]
            questions = []

            for item in data:
                # Support for standard question format
                if "question_id" in item and ("text" in item or "content" in item):
                    # Standard question format
                    question_text = item.get("text") or item.get("content")
                    question = Question(
                        question_id=item["question_id"],
                        content=question_text,
                        # ä¼˜å…ˆä½¿ç”¨ question æ–‡ä»¶ä¸­æ˜¾å¼å†™å…¥çš„ source_documentï¼ˆé€šå¸¸æ˜¯åŸå§‹ .txt è·¯å¾„æˆ–æ–‡æ¡£åï¼‰
                        # å…¶æ¬¡å…¼å®¹æ—§å­—æ®µ source
                        source_document=item.get("source_document")
                        or item.get("source")
                        or questions_file.stem,
                        source_chunk_id=item.get("source_chunk_id", "unknown"),
                        question_index=item.get("question_index", 1),
                        created_at=datetime.now(),
                        metadata={
                            "file": str(questions_file),
                            "question_type": item.get("question_type"),
                            "difficulty": item.get("difficulty"),
                            "category": item.get("category"),
                            "tags": item.get("tags", [])
                        }
                    )
                    questions.append(question)

                # Support for messages format (backward compatibility)
                elif "messages" in item and isinstance(item["messages"], list):
                    for i, msg in enumerate(item["messages"]):
                        # New format: messages is a list of dicts with full Question data
                        if isinstance(msg, dict):
                            question = Question(
                                question_id=msg.get("question_id", f"{questions_file.stem}_{i}"),
                                content=msg.get("content", ""),
                                source_document=msg.get("source_document", questions_file.stem),
                                source_chunk_id=msg.get("source_chunk_id", "unknown"),
                                question_index=msg.get("question_index", i+1),
                                created_at=datetime.fromisoformat(msg["created_at"]) if msg.get("created_at") else datetime.now(),
                                metadata=msg.get("metadata", {})  # åŠ è½½metadataï¼ˆåŒ…å«é¢„ç”Ÿæˆçš„ç­”æ¡ˆï¼‰
                            )
                        # Old format: messages is a list of strings
                        else:
                            question = Question(
                                question_id=f"{questions_file.stem}_{i}",
                                content=str(msg),
                                source_document=questions_file.stem,
                                source_chunk_id="unknown",
                                question_index=i+1,
                                created_at=datetime.now(),
                                metadata={"file": str(questions_file)}
                            )
                        questions.append(question)

            return questions

        except Exception as e:
            raise AnswerServiceError(f"Failed to load questions from {questions_file}: {str(e)}")

    def _load_existing_qa_pairs(self, output_file: Path) -> List[QAPair]:
        """Load existing QA pairs from output file for resuming."""
        try:
            qa_pairs = []

            if not output_file.exists():
                return qa_pairs

            # Load existing QA pairs from file
            jsonl_data = FileUtils.load_jsonl(output_file)

            for item in jsonl_data:
                if isinstance(item, dict) and "messages" in item:
                    # Messages format: {"messages": [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]}
                    messages = item["messages"]

                    # Process messages in pairs (user question, assistant answer)
                    for i in range(0, len(messages), 2):
                        if i + 1 < len(messages):
                            user_msg = messages[i]
                            assistant_msg = messages[i + 1]

                            if user_msg.get("role") == "user" and assistant_msg.get("role") == "assistant":
                                # Create QA pair with synthetic question_id
                                question_id = f"qa_{len(qa_pairs) + 1}"

                                qa_pair = QAPair(
                                    question_id=question_id,
                                    question=user_msg.get("content", ""),
                                    answer=assistant_msg.get("content", ""),
                                    source_document="unknown",
                                    confidence_score=1.0,
                                    metadata={"resumed": True}
                                )
                                qa_pairs.append(qa_pair)

            self.logger.info(f"Loaded {len(qa_pairs)} existing QA pairs from {output_file}")
            return qa_pairs

        except Exception as e:
            error_msg = f"Failed to load existing QA pairs from {output_file}: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e

    def _generate_answers_batch(self, questions: List[Question], session_id: str, output_file: Path = None) -> QASet:
        """Generate answers for a batch of questionsï¼ˆå•æ¬¡å†™å…¥ï¼Œæ— å¢é‡ä¿å­˜ï¼‰."""
        try:
            total_questions = len(questions)
            self.logger.info(f"ğŸš€ å¼€å§‹ä¸º {total_questions} ä¸ªé—®é¢˜ç”Ÿæˆç­”æ¡ˆ")
            
            qa_pairs: List[QAPair] = []
            for i, question in enumerate(questions, 1):
                try:
                    self.logger.info(f"ğŸ“ å¤„ç†é—®é¢˜ {i}/{total_questions}: {question.content[:100]}{'...' if len(question.content) > 100 else ''}")
                    self.logger.info(f"ğŸ†” é—®é¢˜ID: {question.question_id}")
                    
                    # å§‹ç»ˆä½¿ç”¨ RAG ç”Ÿæˆç­”æ¡ˆï¼ˆå……åˆ†åˆ©ç”¨å‘é‡åŒ–å’ŒçŸ¥è¯†å›¾è°±ï¼‰
                    raw_answer = None
                    max_retries = 0
                    
                    # ä½¿ç”¨ RAG æŸ¥è¯¢å¹¶è¿›è¡Œç­”æ¡ˆè´¨é‡éªŒè¯
                    for attempt in range(max_retries + 1):
                        try:
                            raw_answer = self.rag.query_single_question(
                                question.content,
                                source_document=question.source_document,
                            )
                            
                            # Clean <think> tags before validation
                            cleaned_for_validation = self.markdown_processor.clean_llm_response(raw_answer)
                            
                            # è½»é‡åŒ–å¹»è§‰æ£€æµ‹ï¼šä»…è®°å½•å…³é”®æé†’
                            if not self._verify_answer_authenticity(question.content, cleaned_for_validation):
                                self.logger.debug("å¯èƒ½å­˜åœ¨å¹»è§‰ï¼šä»…è®°å½•ï¼Œä¸é˜»æ–­")
                            
                            # Classify answer type
                            answer_type = self._classify_answer_type(cleaned_for_validation)

                            # ä¸å†å› â€œæ— ä¾æ®ç±»ç­”æ¡ˆâ€å¯¼è‡´æ•´é¢˜å¤±è´¥ï¼šå…è®¸è´Ÿå‘/æ— ä¾æ®ç­”æ¡ˆæ­£å¸¸è½ç›˜
                            if answer_type in [AnswerType.VALID_POSITIVE, AnswerType.VALID_NEGATIVE]:
                                break

                            # ä»ç„¶ä¿ç•™æœ€åŸºç¡€çš„å…œåº•ï¼šè®°å½•åç»§ç»­ï¼ˆä¸æŠ›å¼‚å¸¸é˜»æ–­æ•´é¢˜ï¼‰
                            self.logger.warning(
                                "[answers] ç­”æ¡ˆè´¨é‡ä¸ä½³ï¼ŒæŒ‰åŸæ ·ä¿ç•™å¹¶ç»§ç»­: type=%s, preview=%s",
                                getattr(answer_type, "value", str(answer_type)),
                                cleaned_for_validation[:100],
                            )
                            break
                                    
                        except Exception as e:
                            self.logger.warning(f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
                            raise e

                    # Process answer with markdown processor
                    processed_answer = self.markdown_processor.clean_llm_response(raw_answer)

                    qa_pair = QAPair(
                        question_id=question.question_id,
                        question=question.content,
                        answer=processed_answer,
                        source_document=question.source_document,
                        confidence_score=1.0,  # RAG doesn't provide confidence scores
                        metadata={
                            "raw_answer": raw_answer,
                            "processing_session": session_id,
                            "answer_length": len(processed_answer)
                        }
                    )

                    qa_pairs.append(qa_pair)

                    if i % 10 == 0 or i == total_questions:
                        self.logger.info(f"[answers] è¿›åº¦ {i}/{total_questions}")

                    # Update progress only after successful generation
                    self.progress_manager.update_progress(session_id, 1)

                except Exception as e:
                    self.logger.warning(f"[answers] é—®é¢˜ {i}/{total_questions} å¤±è´¥: {e}")
                    self.progress_manager.add_error(session_id, f"Question {question.question_id}: {str(e)}")
                    # Don't update progress for failed questions
                    continue

            # Final saveï¼ˆæ‰¹é‡ä¸€æ¬¡å†™å…¥ï¼‰
            qa_set = QASet(
                document_id=session_id,
                qa_pairs=qa_pairs.copy(),
                created_at=datetime.now()
            )
            if output_file:
                self.logger.info(f"[answers] ä¿å­˜ {len(qa_pairs)} QA å¯¹ -> {output_file}")
                self._save_qa_set(qa_set, output_file)

            # Log generation summary
            total_questions = len(questions)
            successful_qa_pairs = len(qa_pairs)
            failed_questions = total_questions - successful_qa_pairs

            self.logger.info(f"[answers] å®Œæˆ {successful_qa_pairs}/{total_questions}, å¤±è´¥ {failed_questions}")

            return qa_set

        except Exception as e:
            self.logger.error(f"[answers] æ‰¹é‡ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            raise

    def _verify_answer_authenticity(self, question: str, answer: str) -> bool:
        """
        éªŒè¯ç­”æ¡ˆæ˜¯å¦å¯èƒ½åŒ…å«å¹»è§‰ï¼ˆç¼–é€ å†…å®¹ï¼‰
        
        Args:
            question: åŸå§‹é—®é¢˜
            answer: ç”Ÿæˆçš„ç­”æ¡ˆ
            
        Returns:
            bool: Trueè¡¨ç¤ºç­”æ¡ˆå¯ä¿¡ï¼ŒFalseè¡¨ç¤ºå¯èƒ½æœ‰å¹»è§‰
        """
        import re
        
        # å¦‚æœç­”æ¡ˆè¯´æ‰¾ä¸åˆ°ä¿¡æ¯ï¼Œè®¤ä¸ºæ˜¯è¯šå®çš„
        no_info_keywords = ["æœªæ‰¾åˆ°ä¾æ®", "æ— æ³•æ‰¾åˆ°ä¾æ®", "æœªæ£€ç´¢åˆ°", "æ— æ³•æ‰¾åˆ°", "æ‰¾ä¸åˆ°", "æ²¡æœ‰ç›¸å…³ä¿¡æ¯", "æœªæä¾›", "æ–‡æ¡£ä¸­æ²¡æœ‰"]
        if any(kw in answer for kw in no_info_keywords):
            return True
        
        # æå–é—®é¢˜ä¸­çš„å‹å·åç§°
        question_models = set(re.findall(r'[A-Z]{2,}\d+[A-Z]*|[A-Z]+\d+[a-z]*', question))
        
        # æå–ç­”æ¡ˆä¸­çš„å‹å·åç§°
        answer_models = set(re.findall(r'[A-Z]{2,}\d+[A-Z]*|[A-Z]+\d+[a-z]*', answer))
        
        # ğŸš¨ æ£€æµ‹å¹»è§‰ï¼šç­”æ¡ˆä¸­å‡ºç°äº†é—®é¢˜ä¸­æ²¡æœ‰çš„æ–°å‹å·
        new_models = answer_models - question_models
        
        if new_models:
            # ç­”æ¡ˆå¼•å…¥äº†æ–°çš„å‹å·ï¼Œå¯èƒ½æ˜¯å¹»è§‰
            self.logger.warning(f"âš ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„å¹»è§‰ï¼šç­”æ¡ˆä¸­å‡ºç°æ–°å‹å· {new_models}ï¼Œé—®é¢˜åªæåˆ° {question_models}")
            self.logger.warning(f"   é—®é¢˜: {question[:60]}")
            self.logger.warning(f"   ç­”æ¡ˆ: {answer[:100]}")
            return False
        
        # ğŸš¨ æ£€æµ‹æ•°å€¼ä¸ä¸€è‡´
        # æå–é—®é¢˜ä¸­çš„æ•°å­—
        question_numbers = set(re.findall(r'\d+(?:\.\d+)?', question))
        answer_numbers = set(re.findall(r'\d+(?:\.\d+)?', answer))
        
        # å¦‚æœç­”æ¡ˆä¸­çš„æ•°å­—ä¸é—®é¢˜å®Œå…¨ä¸é‡å ï¼Œä¸”ç­”æ¡ˆåŒ…å«æŠ€æœ¯å‚æ•°ï¼Œå¯èƒ½æœ‰é—®é¢˜
        if question_numbers and answer_numbers and not (question_numbers & answer_numbers):
            # æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦åƒæŠ€æœ¯è§„æ ¼ï¼ˆåŒ…å«å•ä½ï¼‰
            has_units = any(unit in answer for unit in ['mm', 'rpm', 'MPa', 'kW', 'kg', 'Â°C', 'Hz'])
            if has_units and len(answer) > 50:
                self.logger.warning(f"âš ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„å¹»è§‰ï¼šç­”æ¡ˆä¸­çš„æ•°å€¼ä¸é—®é¢˜ä¸ä¸€è‡´")
                self.logger.warning(f"   é—®é¢˜æ•°å€¼: {question_numbers}")
                self.logger.warning(f"   ç­”æ¡ˆæ•°å€¼: {answer_numbers}")
                # ä¸ç«‹å³æ‹’ç»ï¼Œåªæ˜¯è­¦å‘Šï¼Œå› ä¸ºå¯èƒ½æ˜¯åˆç†çš„è¡¥å……ä¿¡æ¯
        
        return True
    
    def _classify_answer_type(self, answer: str) -> AnswerType:
        """
        Classify the answer type to determine if it's valid and what kind.
        
        Args:
            answer: Generated answer to classify
            
        Returns:
            AnswerType enum value
        """
        if not answer or not answer.strip():
            return AnswerType.INVALID_ERROR

        answer_stripped = answer.strip()

        # å…ˆå¤„ç†â€œè¯šå®çš„æ— ä¾æ®/æ— ä¿¡æ¯â€å›ç­”ï¼šè¿™åœ¨æœ¬é¡¹ç›®ä¸­æ˜¯å…è®¸çš„æœ‰æ•ˆè´Ÿå‘ç­”æ¡ˆ
        # ï¼ˆä¸ answer_system_prompt çš„â€œæœªæ‰¾åˆ°ä¾æ®â€ç­–ç•¥ä¿æŒä¸€è‡´ï¼‰
        honest_no_info_patterns = [
            "æœªæ‰¾åˆ°ä¾æ®",
            "æ— æ³•æ‰¾åˆ°ä¾æ®",
            "æœªæ£€ç´¢åˆ°ä¾æ®",
            "æœªæ£€ç´¢åˆ°",
            "æ— æ³•ä»æä¾›çš„å†…å®¹ä¸­æ‰¾åˆ°",
            "æ— æ³•ä»çŸ¥è¯†åº“ä¸­æ‰¾åˆ°",
            "æ–‡æ¡£ä¸­æ²¡æœ‰",
            "æ–‡æ¡£ä¸­æœªåŒ…å«",
            "æ–‡æ¡£ä¸­æœªæåŠ",
            "æœªæä¾›",
            "æ²¡æœ‰æä¾›",
            "æ²¡æœ‰ç›¸å…³ä¿¡æ¯",
            "æ‰¾ä¸åˆ°",
            "æœªæ‰¾åˆ°",
            "æœªèƒ½æ‰¾åˆ°",
        ]
        if any(p in answer_stripped for p in honest_no_info_patterns):
            return AnswerType.VALID_NEGATIVE
        
        # First, check for technical negatives (valuable answers)
        technical_negative_patterns = [
            "ä¸æ”¯æŒ", "ä¸å…·å¤‡", "ä¸åŒ…æ‹¬", "ä¸åŒ…å«", "ä¸é€‚ç”¨", "ä¸å…¼å®¹",
            "æ— éœ€", "æ— æ­¤", "æ²¡æœ‰æ­¤", "ä¸éœ€è¦", "ä¸å¿…",
            "ç¦æ­¢", "ä¸å…è®¸", "ä¸èƒ½", "ä¸å¯",
            "é", "å¦", "æœªè®¾ç½®", "æœªé…ç½®",
        ]
        
        for pattern in technical_negative_patterns:
            if pattern in answer:
                # æŠ€æœ¯æ€§å¦å®šä¸è¦æ±‚å¾ˆé•¿ï¼ˆå¸¸è§çš„æ˜¯ä¸€å¥è¯â€œXXä¸æ”¯æŒYYâ€ï¼‰
                return AnswerType.VALID_NEGATIVE

        # Check for common error messages and "no information" responses
        no_info_patterns = [
            # æŸ¥è¯¢é”™è¯¯
            "æŸ¥è¯¢è¶…æ—¶",
            "è¯·ç¨åé‡è¯•",
            "æŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜",
            "æ— æ³•ç”Ÿæˆç­”æ¡ˆ",
            
            # "æ— æ³•æ‰¾åˆ°"ç›¸å…³
            "æ— æ³•ä»çŸ¥è¯†åº“ä¸­æ‰¾åˆ°",
            "æ— æ³•æ‰¾åˆ°",
            "æ‰¾ä¸åˆ°",
            "æ²¡æœ‰æ‰¾åˆ°",
            "æœªæ‰¾åˆ°",
            "æ— æ³•æ‰¾åˆ°å…³äº",
            "ç›®å‰æ— æ³•æ‰¾åˆ°",
            "æœªèƒ½æ‰¾åˆ°",
            "æ— æ³•è·å–",
            
            # "æ²¡æœ‰ä¿¡æ¯"ç›¸å…³
            "æ²¡æœ‰ç›¸å…³ä¿¡æ¯",
            "æ²¡æœ‰ç›¸å…³çš„",
            "ç¼ºä¹ç›¸å…³",
            "ç¼ºä¹è¯¦ç»†",
            "æ²¡æœ‰è¯¦ç»†",
            "æ²¡æœ‰æ˜ç¡®",
            "æ²¡æœ‰å…·ä½“",
            "æœªæä¾›",
            "æ²¡æœ‰æä¾›",
            "æ²¡æœ‰ç»™å‡º",
            "æœªç»™å‡º",
            
            # "æ–‡æ¡£ä¸­æ²¡æœ‰"ç›¸å…³
            "æ–‡æ¡£ä¸­æœªåŒ…å«",
            "æ–‡æ¡£ä¸­æ²¡æœ‰",
            "æ–‡æ¡£ä¸­æœªæåŠ",
            "æ–‡æ¡£æœªæ¶‰åŠ",
            "æ–‡æ¡£ä¸­ç¼ºä¹",
            "çŸ¥è¯†åº“ä¸­ç¼ºä¹",
            "æä¾›çš„ä¿¡æ¯ä¸­æ²¡æœ‰",
            "æ‰€æä¾›çš„å†…å®¹ä¸­æ²¡æœ‰",
            
            # "æ ¹æ®æä¾›çš„ä¿¡æ¯"åè·Ÿå¦å®š
            "æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œç›®å‰æ²¡æœ‰",
            "æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ²¡æœ‰",
            "æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ— æ³•",
            "æ ¹æ®æä¾›çš„èµ„æ–™ï¼Œæ²¡æœ‰",
            "æ ¹æ®æä¾›çš„æ–‡æ¡£ï¼Œæ²¡æœ‰",
            "æ ¹æ®ç°æœ‰ä¿¡æ¯ï¼Œæ²¡æœ‰",
            "æ ¹æ®ç°æœ‰èµ„æ–™ï¼Œæ²¡æœ‰",
            
            # å»ºè®®æ€§å›å¤ï¼ˆè¡¨ç¤ºæ²¡æœ‰ç­”æ¡ˆï¼‰
            "å»ºè®®æŸ¥é˜…",
            "å»ºè®®è”ç³»",
            "å»ºè®®å‚è€ƒ",
            "å»ºè®®å’¨è¯¢",
            "è¯·æŸ¥é˜…",
            "è¯·è”ç³»",
            "è¯·å‚è€ƒ",
            "è¯·å’¨è¯¢",
            
            # ç‰¹å®šå‹å·ç›¸å…³
            "æœªåŒ…å«è¯¥ç‰¹å®šå‹å·",
            "æœªæ¶‰åŠè¯¥ç‰¹å®šå‹å·",
            "æ²¡æœ‰æ¶‰åŠè¯¥å‹å·",
            "æœªæ¶‰åŠè¯¥å‹å·",
            "æœªåŒ…å«è¯¥å‹å·",
            
            # è‹±æ–‡é”™è¯¯æ¨¡å¼
            "Error:",
            "æŠ±æ­‰",
            "Sorry",
            "I don't have",
            "I cannot",
            "I can't",
            "No information",
            "not found",
            "unable to find",
            "does not contain",
            "does not provide",
            "not provided",
            "not mentioned",
            "not specified",
            
            # å…¶ä»–å¦å®šè¡¨è¿°
            "ç¼ºå°‘",
            "ç¼ºå¤±",
            "ä¸è¶³ä»¥å›ç­”",
            "æ— æ³•å›ç­”",
            "éš¾ä»¥å›ç­”",
        ]

        answer_lower = answer.lower().strip()
        for pattern in no_info_patterns:
            if pattern.lower() in answer_lower:
                self.logger.debug(f"Answer classified as NO_INFO: contains pattern '{pattern}'")
                return AnswerType.INVALID_NO_INFO
        
        # æ£€æŸ¥ç­”æ¡ˆå¼€å¤´æ˜¯å¦æ˜ç¡®è¡¨ç¤ºæ²¡æœ‰ä¿¡æ¯
        negative_starts = [
            "æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œç›®å‰æ²¡æœ‰",
            "æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ²¡æœ‰",
            "æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ— æ³•",
            "æ ¹æ®æ‰€æä¾›çš„ä¿¡æ¯ï¼Œæ²¡æœ‰",
            "æ ¹æ®æ–‡æ¡£ï¼Œæ²¡æœ‰",
            "æ ¹æ®æ–‡æ¡£ï¼Œæ— æ³•",
            "å¾ˆæŠ±æ­‰",
            "æŠ±æ­‰",
        ]
        
        for negative_start in negative_starts:
            if answer.strip().startswith(negative_start):
                self.logger.debug(f"Answer classified as NO_INFO: starts with negative phrase '{negative_start}'")
                return AnswerType.INVALID_NO_INFO

        # Check if answer is too short (likely an error message or incomplete answer)
        # But allow short answers if they contain technical content (numbers, units, specific terms)
        answer_stripped = answer.strip()
        if len(answer_stripped) < 50:  # Very short answers need extra validation
            # Check if it contains technical content markers
            import re
            has_numbers = bool(re.search(r'\d', answer_stripped))
            has_units = bool(re.search(r'(mm|cm|m|kg|r/min|rpm|Hz|kW|V|A|Â°C|MPa|%)', answer_stripped, re.IGNORECASE))
            has_colon = ':' in answer_stripped or 'ï¼š' in answer_stripped
            
            # If it has technical content markers, it's likely valid despite being short
            if not (has_numbers or has_units or has_colon):
                self.logger.debug(f"Answer classified as ERROR: too short and lacks technical content ({len(answer_stripped)} chars)")
                return AnswerType.INVALID_ERROR
        
        # æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦ä¸»è¦ç”±"æ— æ³•å›ç­”"ç±»å‹çš„å¦å®šè¯ç»„æˆ
        # ä½†è¦æ’é™¤é‚£äº›ç»™å‡ºå…·ä½“å¦å®šç­”æ¡ˆçš„æƒ…å†µï¼ˆå¦‚"è¯¥è®¾å¤‡ä¸æ”¯æŒXXåŠŸèƒ½"ï¼‰
        sentences = [s.strip() for s in answer.replace('ã€‚', '.').replace('ï¼', '!').replace('ï¼Ÿ', '?').split('.') if s.strip()]
        if len(sentences) > 1:  # åªå¯¹å¤šå¥å­ç­”æ¡ˆæ£€æŸ¥ï¼ˆå•å¥ç­”æ¡ˆå¯èƒ½å°±æ˜¯ç®€æ´çš„å¦å®šå›ç­”ï¼‰
            # åªæ£€æŸ¥é‚£äº›è¡¨ç¤º"æ— æ³•å›ç­”"çš„å¦å®šè¯ï¼Œè€Œä¸æ˜¯æ­£å¸¸çš„æŠ€æœ¯å¦å®šæè¿°
            meta_negative_phrases = [
                "æ²¡æœ‰ç›¸å…³", "æ²¡æœ‰æä¾›", "æ²¡æœ‰ç»™å‡º", "æ²¡æœ‰è¯´æ˜", "æ²¡æœ‰æåŠ", "æ²¡æœ‰æ¶‰åŠ",
                "æ— æ³•æ‰¾åˆ°", "æ— æ³•ç¡®å®š", "æ— æ³•è·å–", "æ— æ³•å›ç­”",
                "æœªæä¾›", "æœªç»™å‡º", "æœªè¯´æ˜", "æœªæåŠ",
                "ç¼ºä¹ç›¸å…³", "ç¼ºå°‘", "ç¼ºå¤±",
                "ä¸è¶³ä»¥å›ç­”", "éš¾ä»¥å›ç­”"
            ]
            negative_sentence_count = sum(1 for s in sentences if any(phrase in s for phrase in meta_negative_phrases))
            if negative_sentence_count / len(sentences) > 0.5:  # è¶…è¿‡50%çš„å¥å­å«"æ— æ³•å›ç­”"ç±»å‹çš„å¦å®š
                self.logger.debug(f"Answer classified as NO_INFO: too many meta-negative sentences ({negative_sentence_count}/{len(sentences)})")
                return AnswerType.INVALID_NO_INFO

        # If we get here, the answer is valid and positive
        return AnswerType.VALID_POSITIVE

    def _save_qa_set(self, qa_set: QASet, output_file: Path) -> None:
        """Save QA set to JSONL file (single-line JSON per QA)."""
        try:
            # Ensure output directory exists
            FileUtils.ensure_directory(output_file.parent)

            with open(output_file, 'w', encoding='utf-8') as f:
                for qa_pair in qa_set.qa_pairs:
                    qa_data = {
                        "question": qa_pair.question,
                        "answer": qa_pair.answer,
                        "source_document": qa_pair.source_document,
                        "question_id": qa_pair.question_id,
                        "confidence_score": qa_pair.confidence_score,
                        "metadata": qa_pair.metadata,
                        "created_at": qa_pair.created_at.isoformat() if qa_pair.created_at else None
                    }
                    f.write(json.dumps(qa_data, ensure_ascii=False))
                    f.write("\n")

            self.logger.info(f"QA set saved to: {output_file} ({len(qa_set.qa_pairs)} QA pairs)")

        except Exception as e:
            self.logger.error(f"Failed to save QA set: {e}")
            raise

    def generate_answers_from_existing_kb(
            self,
            questions_file: Path,
            working_dir: Path,
            output_file: Path,
            session_id: Optional[str] = None,
            resume: bool = True
    ) -> QASet:
        """
        Generate answers using an existing knowledge base.
        
        Args:
            questions_file: Path to questions JSONL file
            working_dir: Working directory containing existing knowledge base
            output_file: Path to output QA JSONL file
            session_id: Optional session ID for progress tracking
            resume: Whether to resume from existing progress (default: True)
            
        Returns:
            QASet containing generated QA pairs
            
        Raises:
            AnswerServiceError: If answer generation fails
        """
        try:
            # Create session if not provided
            if session_id is None:
                session_id = f"answer_gen_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            self.logger.info(f"Generating answers from existing knowledge base: {working_dir}")

            # Use existing knowledge base
            self.rag.use_existing_knowledge_base(working_dir)

            # Load questions
            all_questions = self._load_questions_from_file(questions_file)
            if not all_questions:
                raise AnswerServiceError(f"No questions found in {questions_file}")

            # Check for resume
            questions_to_process = all_questions
            existing_qa_pairs = []

            if resume and output_file.exists():
                try:
                    existing_qa_pairs = self._load_existing_qa_pairs(output_file)
                    processed_question_ids = {qa.question_id for qa in existing_qa_pairs}
                    questions_to_process = [q for q in all_questions if q.question_id not in processed_question_ids]

                    self.logger.info(f"Resuming from {len(existing_qa_pairs)} existing QA pairs, "
                                     f"{len(questions_to_process)} questions remaining")
                except Exception as e:
                    self.logger.warning(f"Failed to load existing progress: {e}, starting fresh")
                    questions_to_process = all_questions
                    existing_qa_pairs = []

            # Initialize or update progress
            if resume and self.progress_manager.get_session_progress(session_id):
                # Session exists, continue
                self.logger.info(f"Continuing existing session: {session_id}")
            else:
                # New session
                self.progress_manager.start_session(
                    session_id=session_id,
                    total_items=len(all_questions),
                    operation_type="answer_generation"
                )

            # Update progress for existing pairs
            if existing_qa_pairs:
                self.progress_manager.update_progress(session_id, len(existing_qa_pairs))

            # Generate answers for remaining questions
            if questions_to_process:
                new_qa_set = self._generate_answers_batch(questions_to_process, session_id, output_file)
                new_qa_pairs = new_qa_set.qa_pairs
            else:
                new_qa_pairs = []

            # Combine existing and new QA pairs
            all_qa_pairs = existing_qa_pairs + new_qa_pairs

            # Create final QA set
            qa_set = QASet(
                document_id=session_id,
                qa_pairs=all_qa_pairs,
                created_at=datetime.now()
            )

            # Save final results
            if not resume or new_qa_pairs:  # Only save if not resuming or if we have new pairs
                self._save_qa_set(qa_set, output_file)

            # Complete session
            self.progress_manager.complete_session(session_id)

            self.logger.info(f"Answer generation completed: {len(qa_set.qa_pairs)} total QA pairs "
                             f"({len(existing_qa_pairs)} existing + {len(new_qa_pairs)} new)")
            return qa_set

        except Exception as e:
            if session_id:
                self.progress_manager.fail_session(session_id, str(e))
            error_msg = f"Failed to generate answers: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e


class AnswerServiceError(Exception):
    """Custom exception for answer service errors."""
    pass 