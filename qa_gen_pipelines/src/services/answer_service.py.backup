"""Answer generation service."""

import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import json
import signal
import sys
import atexit
import threading

from ..interfaces.rag_interface import RAGInterface, RAGError
from ..interfaces.markdown_processor_interface import MarkdownProcessorInterface
from ..models.document import Document
from ..models.question import Question, QuestionSet
from ..models.qa_pair import QAPair, QASet
from ..utils.file_utils import FileUtils
from .progress_manager import ProgressManager


class AnswerService:
    """Service for generating answers using RAG with incremental saving."""
    
    def __init__(
        self,
        rag: RAGInterface,
        markdown_processor: MarkdownProcessorInterface,
        progress_manager: ProgressManager,
        logger: Optional[logging.Logger] = None
    ):
        """
        Initialize the answer service.
        
        Args:
            rag: RAG implementation for answer generation
            markdown_processor: Markdown processor for cleaning answers
            progress_manager: Progress manager for tracking operations
            logger: Optional logger instance
        """
        self.rag = rag
        self.markdown_processor = markdown_processor
        self.progress_manager = progress_manager
        self.logger = logger or logging.getLogger(__name__)
        
        # Incremental saving state
        self._current_qa_pairs = []
        self._current_output_file = None
        self._current_session_id = None
        self._save_interval = 5  # Save every 5 QA pairs
        self._autosave_lock = threading.Lock()
        
        # Setup signal handlers for graceful shutdown
        self._setup_signal_handlers()
        
        # Register cleanup function
        atexit.register(self._cleanup_on_exit)
        
    def _setup_signal_handlers(self):
        """Setup signal handlers for graceful shutdown."""
        def signal_handler(signum, frame):
            self.logger.warning(f"Received signal {signum}, performing graceful shutdown...")
            self._save_current_progress()
            sys.exit(0)
        
        # Handle common termination signals
        signal.signal(signal.SIGINT, signal_handler)   # Ctrl+C
        signal.signal(signal.SIGTERM, signal_handler)  # Termination request
        
        # On Windows, also handle SIGBREAK
        if sys.platform == "win32":
            signal.signal(signal.SIGBREAK, signal_handler)
    
    def _cleanup_on_exit(self):
        """Cleanup function called on program exit."""
        try:
            self._save_current_progress()
        except Exception as e:
            self.logger.error(f"Error during cleanup: {e}")
    
    def _save_current_progress(self):
        """Save current progress to file."""
        with self._autosave_lock:
            if self._current_qa_pairs and self._current_output_file:
                try:
                    # Create temporary QA set
                        qa_set = QASet(
                        document_id=self._current_session_id or "interrupted_session",
                        qa_pairs=self._current_qa_pairs.copy(),
                        created_at=datetime.now()
                    )
                    
                    # Save to temporary file first
                    temp_file = self._current_output_file.with_suffix('.temp.jsonl')
                    self._save_qa_set(qa_set, temp_file)
                    
                    # Move to final location (Windows compatible)
                    if temp_file.exists():
                        # Use replace() for cross-platform compatibility
                        # replace() works on all platforms and overwrites existing files
                        temp_file.replace(self._current_output_file)
                        self.logger.info(f"Progress saved: {len(self._current_qa_pairs)} QA pairs to {self._current_output_file}")
                    
                    # Update progress manager
                    if self._current_session_id:
                        self.progress_manager.save_progress()
                        
                    except Exception as e:
                        self.logger.error(f"Failed to save progress: {e}")
    
    def _incremental_save(self, force=False):
        """Perform incremental save if conditions are met."""
        if not force and len(self._current_qa_pairs) % self._save_interval != 0:
            return
            
        self._save_current_progress()
        
    def setup_knowledge_base(self, documents_path: Path, working_dir: Optional[Path] = None) -> None:
        """
        Setup the knowledge base with documents.
        
        Args:
            documents_path: Path to directory containing processed documents
            working_dir: Working directory for the knowledge base
            
        Raises:
            AnswerServiceError: If setup fails
        """
        try:
            self.logger.info(f"Setting up knowledge base from: {documents_path}")
            
            if working_dir:
                # Check if working directory exists and has data
                if working_dir.exists() and any(working_dir.glob("*.json")):
                    # Working directory exists with data - append to existing KB
                    self.logger.info(f"Appending to existing knowledge base: {working_dir}")
                    self.rag.use_existing_knowledge_base(working_dir)
                else:
                    # Working directory doesn't exist or is empty - create new KB
                    self.logger.info(f"Creating new knowledge base: {working_dir}")
                    self.rag.set_working_directory(working_dir)
            else:
                # No working directory specified - clear default KB
                self.logger.info("Using default working directory with clean KB")
                self.rag.clear_knowledge_base()
            
            # Load documents from directory
            if documents_path.is_file() and documents_path.suffix == '.txt':
                # Single document
                document = self._load_document_from_file(documents_path)
                self.rag.insert_document(document)
            elif documents_path.is_dir():
                # Directory of documents
                documents = self._load_documents_from_directory(documents_path)
                if documents:
                    self.rag.insert_documents_batch(documents)
                else:
                    raise AnswerServiceError(f"No valid documents found in {documents_path}")
            else:
                raise AnswerServiceError(f"Invalid documents path: {documents_path}")
                
            # Get knowledge base stats
            stats = self.rag.get_knowledge_base_stats()
            self.logger.info(f"Knowledge base setup complete: {stats}")
            
        except Exception as e:
            error_msg = f"Failed to setup knowledge base: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e
    
    def generate_answers_for_questions(
        self,
        questions_file: Path,
        output_file: Path,
        session_id: Optional[str] = None,
        resume: bool = True
    ) -> QASet:
        """
        Generate answers for questions from a file.
        
        Args:
            questions_file: Path to questions JSONL file
            output_file: Path to output QA JSONL file
            session_id: Optional session ID for progress tracking
            resume: Whether to resume from existing progress (default: True)
            
        Returns:
            QASet containing generated QA pairs
            
        Raises:
            AnswerServiceError: If answer generation fails
        """
        try:
            # Create session if not provided
            if session_id is None:
                session_id = f"answer_gen_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            self.logger.info(f"Starting answer generation session: {session_id}")
            
            # Load questions
            all_questions = self._load_questions_from_file(questions_file)
            if not all_questions:
                raise AnswerServiceError(f"No questions found in {questions_file}")
            
            # Check for resume
            questions_to_process = all_questions
            existing_qa_pairs = []
            
            if resume and output_file.exists():
                try:
                    existing_qa_pairs = self._load_existing_qa_pairs(output_file)
                    processed_question_ids = {qa.question_id for qa in existing_qa_pairs}
                    questions_to_process = [q for q in all_questions if q.question_id not in processed_question_ids]
                    
                    self.logger.info(f"Resuming from {len(existing_qa_pairs)} existing QA pairs, "
                                   f"{len(questions_to_process)} questions remaining")
                    except Exception as e:
                    self.logger.warning(f"Failed to load existing progress: {e}, starting fresh")
                    questions_to_process = all_questions
                    existing_qa_pairs = []
            
            # Initialize or update progress
            if resume and self.progress_manager.get_session_progress(session_id):
                # Session exists, continue
                self.logger.info(f"Continuing existing session: {session_id}")
            else:
                # New session
                self.progress_manager.start_session(
                    session_id=session_id,
                    total_items=len(all_questions),
                    operation_type="answer_generation"
                )
            
            # Update progress for existing pairs
            if existing_qa_pairs:
                    self.progress_manager.update_progress(session_id, len(existing_qa_pairs))
            
            # Generate answers for remaining questions
            if questions_to_process:
                new_qa_set = self._generate_answers_batch(questions_to_process, session_id, output_file)
                new_qa_pairs = new_qa_set.qa_pairs
            else:
                new_qa_pairs = []
            
            # Combine existing and new QA pairs
            all_qa_pairs = existing_qa_pairs + new_qa_pairs
            
            # Create final QA set
                qa_set = QASet(
                document_id=session_id,
                qa_pairs=all_qa_pairs,
                created_at=datetime.now()
            )
            
            # Save final results
            if not resume or new_qa_pairs:  # Only save if not resuming or if we have new pairs
                self._save_qa_set(qa_set, output_file)
            
            # Complete session
            self.progress_manager.complete_session(session_id)
            
            self.logger.info(f"Answer generation completed: {len(qa_set.qa_pairs)} total QA pairs "
                           f"({len(existing_qa_pairs)} existing + {len(new_qa_pairs)} new)")
                return qa_set
            
        except Exception as e:
            if session_id:
                self.progress_manager.fail_session(session_id, str(e))
            error_msg = f"Failed to generate answers: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e
    
    def generate_answers_for_directory(
        self,
        questions_dir: Path,
        output_dir: Path,
        session_id: Optional[str] = None
    ) -> Dict[str, QASet]:
        """
        Generate answers for all question files in a directory.
        
        Args:
            questions_dir: Directory containing question JSONL files
            output_dir: Directory for output QA JSONL files
            session_id: Optional session ID for progress tracking
            
        Returns:
            Dictionary mapping file names to QASet objects
            
        Raises:
            AnswerServiceError: If batch processing fails
        """
        try:
            # Create session if not provided
            if session_id is None:
                session_id = f"answer_batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            self.logger.info(f"Starting batch answer generation: {session_id}")
            
            # Find question files
            question_files = list(questions_dir.glob("*questions.jsonl"))
            if not question_files:
                raise AnswerServiceError(f"No question files found in {questions_dir}")
            
            # Create output directory
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # Initialize progress
            self.progress_manager.start_session(
                session_id=session_id,
                total_items=len(question_files),
                operation_type="batch_answer_generation"
            )
            
            results = {}
            
            for question_file in question_files:
                try:
                    # Generate output filename
                    base_name = question_file.stem.replace("_questions", "")
                    output_file = output_dir / f"{base_name}_qa.jsonl"
                    
                    # Generate answers
                    qa_set = self.generate_answers_for_questions(
                        question_file, output_file, f"{session_id}_{base_name}"
                    )
                    
                    results[question_file.name] = qa_set
                    
                    # Update progress
                        self.progress_manager.update_progress(session_id, 1)
                    
                    except Exception as e:
                        self.logger.error(f"Failed to process {question_file}: {str(e)}")
                        self.progress_manager.add_error(session_id, f"{question_file.name}: {str(e)}")
                        continue
            
            # Complete session
            self.progress_manager.complete_session(session_id)
            
            self.logger.info(f"Batch answer generation completed: {len(results)} files processed")
            return results
            
        except Exception as e:
            if session_id:
                self.progress_manager.fail_session(session_id, str(e))
            error_msg = f"Failed to process directory: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e
    
    def resume_answer_generation(self, session_id: str) -> Optional[QASet]:
        """
        Resume a failed answer generation session.
        
        Args:
            session_id: Session ID to resume
            
        Returns:
            QASet if resumption successful, None otherwise
            
        Raises:
            AnswerServiceError: If resumption fails
        """
        try:
            session = self.progress_manager.get_session(session_id)
            if not session:
                raise AnswerServiceError(f"Session not found: {session_id}")
            
            if session.status == "completed":
                self.logger.info(f"Session {session_id} already completed")
                return None
            
            self.logger.info(f"Resuming answer generation session: {session_id}")
            
            # Resume logic would depend on how we store intermediate results
            # For now, we'll just log that resumption is not implemented
            self.logger.warning("Answer generation resumption not yet implemented")
            return None
            
        except Exception as e:
            error_msg = f"Failed to resume session {session_id}: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e
    
    def get_knowledge_base_info(self) -> Dict[str, Any]:
        """
        Get information about the current knowledge base.
        
        Returns:
            Dictionary containing knowledge base information
        """
        try:
            return self.rag.get_knowledge_base_stats()
        except Exception as e:
            self.logger.error(f"Failed to get knowledge base info: {str(e)}")
            return {"error": str(e)}
    
    def _load_document_from_file(self, file_path: Path) -> Document:
        """Load a single document from file."""
        content = file_path.read_text(encoding='utf-8')
        return Document(
            file_path=file_path,
            content=content,
            file_type=file_path.suffix,
            file_size=len(content),
            created_at=datetime.fromtimestamp(file_path.stat().st_ctime),
            processed_at=datetime.now()
        )
    
    def _load_documents_from_directory(self, directory_path: Path) -> List[Document]:
        """Load all documents from a directory."""
        documents = []
        
        for file_path in directory_path.glob("*.txt"):
            try:
                document = self._load_document_from_file(file_path)
                documents.append(document)
                except Exception as e:
                self.logger.warning(f"Failed to load document {file_path}: {str(e)}")
                    continue
        
        return documents
    
    def _load_questions_from_file(self, questions_file: Path) -> List[Question]:
        """Load questions from JSONL file."""
        try:
            data = FileUtils.load_jsonl(questions_file)
            questions = []
            
            for item in data:
                # Support for standard question format
                if "question_id" in item and ("text" in item or "content" in item):
                    # Standard question format
                    question_text = item.get("text") or item.get("content")
                    question = Question(
                        question_id=item["question_id"],
                        content=question_text,
                        source_document=item.get("source", questions_file.stem),
                        source_chunk_id=item.get("source_chunk_id", "unknown"),
                        question_index=item.get("question_index", 1),
                        created_at=datetime.now(),
                        metadata={
                            "file": str(questions_file),
                            "question_type": item.get("question_type"),
                            "difficulty": item.get("difficulty"),
                            "category": item.get("category"),
                            "tags": item.get("tags", [])
                        }
                    )
                    questions.append(question)
                
                # Support for messages format (backward compatibility)
                elif "messages" in item and isinstance(item["messages"], list):
                    for i, question_text in enumerate(item["messages"]):
                        question = Question(
                            question_id=f"{questions_file.stem}_{i}",
                            content=question_text,
                            source_document=questions_file.stem,
                            source_chunk_id="unknown",
                            question_index=i+1,
                            created_at=datetime.now(),
                            metadata={"file": str(questions_file)}
                        )
                        questions.append(question)
            
            return questions
            
        except Exception as e:
            raise AnswerServiceError(f"Failed to load questions from {questions_file}: {str(e)}")
    
    def _load_existing_qa_pairs(self, output_file: Path) -> List[QAPair]:
        """Load existing QA pairs from output file for resuming."""
        try:
            qa_pairs = []
            
            if not output_file.exists():
                return qa_pairs
            
            # Load existing QA pairs from file
            jsonl_data = FileUtils.load_jsonl(output_file)
            
            for item in jsonl_data:
                if isinstance(item, dict) and "messages" in item:
                    # Messages format: {"messages": [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]}
                    messages = item["messages"]
                    
                    # Process messages in pairs (user question, assistant answer)
                    for i in range(0, len(messages), 2):
                        if i + 1 < len(messages):
                            user_msg = messages[i]
                            assistant_msg = messages[i + 1]
                            
                            if user_msg.get("role") == "user" and assistant_msg.get("role") == "assistant":
                                    # Create QA pair with synthetic question_id
                                question_id = f"qa_{len(qa_pairs) + 1}"
                                
                                    qa_pair = QAPair(
                                    question_id=question_id,
                                    question=user_msg.get("content", ""),
                                    answer=assistant_msg.get("content", ""),
                                    source_document="unknown",
                                    confidence_score=1.0,
                                    metadata={"resumed": True}
                                )
                                qa_pairs.append(qa_pair)
            
            self.logger.info(f"Loaded {len(qa_pairs)} existing QA pairs from {output_file}")
            return qa_pairs
            
        except Exception as e:
            error_msg = f"Failed to load existing QA pairs from {output_file}: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e
    
    def _generate_answers_batch(self, questions: List[Question], session_id: str, output_file: Path = None) -> QASet:
        """Generate answers for a batch of questions with incremental saving."""
        # Initialize incremental saving state
        self._current_qa_pairs = []
        self._current_output_file = output_file
        self._current_session_id = session_id
        
                try:
            for question in questions:
                try:
                    # Generate answer using RAG
                    raw_answer = self.rag.query_single_question(question.content)
                    
                    # Validate answer quality (check for error messages or too short answers)
                    if self._is_answer_invalid(raw_answer):
                        raise ValueError(f"Invalid answer generated: {raw_answer[:100]}...")
                        
                        # Process answer with markdown processor
                        processed_answer = self.markdown_processor.clean_llm_response(raw_answer)
                    
                        # Create QA pair
                        qa_pair = QAPair(
                        question_id=question.question_id,
                        question=question.content,
                        answer=processed_answer,
                        source_document=question.source_document,
                        confidence_score=1.0,  # RAG doesn't provide confidence scores
                        metadata={
                            "raw_answer": raw_answer,
                            "processing_session": session_id,
                            "answer_length": len(processed_answer)
                        }
                    )
                    
                    # Add to current pairs and perform incremental save
                    with self._autosave_lock:
                        self._current_qa_pairs.append(qa_pair)
                    
                    # Perform incremental save
                    self._incremental_save()
                    
                    self.logger.debug(f"Generated answer for question {question.question_id} ({len(processed_answer)} chars)")
                
                    # Update progress only after successful generation
                        self.progress_manager.update_progress(session_id, 1)
                    
                    except Exception as e:
                        self.logger.error(f"Failed to generate answer for question {question.question_id}: {str(e)}")
                        self.progress_manager.add_error(session_id, f"Question {question.question_id}: {str(e)}")
                    # Don't update progress for failed questions
                        continue
            
            # Final save
            self._incremental_save(force=True)
            
            # Log generation summary
            total_questions = len(questions)
            successful_qa_pairs = len(self._current_qa_pairs)
            failed_questions = total_questions - successful_qa_pairs
            
            self.logger.info(f"Answer generation summary: {successful_qa_pairs}/{total_questions} successful, {failed_questions} failed")
            
            if failed_questions > 0:
                self.logger.warning(f"Some questions failed to generate answers. Check logs for details.")
            
                # Create QA set
                qa_set = QASet(
                document_id=session_id,
                qa_pairs=self._current_qa_pairs.copy(),
                created_at=datetime.now()
            )
            
                return qa_set
            
        finally:
            # Clear incremental saving state
            self._current_qa_pairs = []
            self._current_output_file = None
            self._current_session_id = None
    
    def _is_answer_invalid(self, answer: str) -> bool:
        """
        Check if the generated answer is invalid (error message, too short, etc.).
        
        Args:
            answer: Generated answer to validate
            
        Returns:
            True if answer is invalid, False otherwise
        """
        if not answer or not answer.strip():
            return True
        
        # Check for common error messages
        error_patterns = [
            "查询超时",
            "请稍后重试",
            "无法从知识库中找到",
            "查询过程中出现问题",
            "无法生成答案",
            "Error:",
            "抱歉，",
            "Sorry,",
            "I don't have",
            "I cannot",
            "No information"
        ]
        
        answer_lower = answer.lower().strip()
        for pattern in error_patterns:
            if pattern.lower() in answer_lower:
                return True
        
        # Check if answer is too short (likely an error message)
        if len(answer.strip()) < 100:  # Answers shorter than 100 chars are likely errors
            return True
        
        return False
    
    def _save_qa_set(self, qa_set: QASet, output_file: Path) -> None:
        """Save QA set to JSONL file in messages format."""
        try:
            # Convert QA pairs to messages format
            messages = []
            for qa_pair in qa_set.qa_pairs:
                # Add user message (question)
                messages.append({
                    "role": "user",
                    "content": qa_pair.question
                })
                # Add assistant message (answer)
                messages.append({
                    "role": "assistant", 
                    "content": qa_pair.answer
                })
            
            # Create the final format - one line with all messages
            jsonl_data = {"messages": messages}
            
            # Ensure output directory exists
            FileUtils.ensure_directory(output_file.parent)
            
            # Save to file
            FileUtils.save_jsonl_file([jsonl_data], output_file)
            
            self.logger.info(f"QA set saved to: {output_file} ({len(qa_set.qa_pairs)} QA pairs in messages format)")
            
        except Exception as e:
            raise AnswerServiceError(f"Failed to save QA set: {str(e)}")
    
    def insert_documents_to_working_dir(
        self,
        documents_path: Path,
        working_dir: Path,
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Insert documents into a specific working directory.
        
        Args:
            documents_path: Path to directory containing documents or single document
            working_dir: Working directory for the knowledge base
            session_id: Optional session ID for progress tracking
            
        Returns:
            Dictionary containing insertion statistics
            
        Raises:
            AnswerServiceError: If insertion fails
        """
        try:
            # Create session if not provided
            if session_id is None:
                session_id = f"insert_docs_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            self.logger.info(f"Inserting documents to working directory: {working_dir}")
            
            # Set working directory for RAG
            self.rag.set_working_directory(working_dir)
            
            # Load documents
            if documents_path.is_file() and documents_path.suffix == '.txt':
                # Single document
                documents = [self._load_document_from_file(documents_path)]
            elif documents_path.is_dir():
                # Directory of documents
                documents = self._load_documents_from_directory(documents_path)
            else:
                raise AnswerServiceError(f"Invalid documents path: {documents_path}")
            
            if not documents:
                raise AnswerServiceError(f"No valid documents found in {documents_path}")
            
            # Initialize progress
            self.progress_manager.start_session(
                session_id=session_id,
                total_items=len(documents),
                operation_type="document_insertion"
            )
            
            # Insert documents
            success_count = 0
            error_count = 0
            
            for document in documents:
                try:
                    self.rag.insert_document(document)
                    success_count += 1
                        self.progress_manager.update_progress(session_id, 1)
                    except Exception as e:
                    error_count += 1
                        self.logger.error(f"Failed to insert document {document.name}: {str(e)}")
                        self.progress_manager.add_error(session_id, f"{document.name}: {str(e)}")
                        continue
            
            # Complete session
            self.progress_manager.complete_session(session_id)
            
            # Get final stats
            stats = self.rag.get_knowledge_base_stats()
            stats.update({
                "inserted_documents": success_count,
                "failed_documents": error_count,
                "total_attempted": len(documents)
            })
            
            self.logger.info(f"Document insertion completed: {success_count} success, {error_count} failed")
            return stats
            
        except Exception as e:
            if session_id:
                self.progress_manager.fail_session(session_id, str(e))
            error_msg = f"Failed to insert documents: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e
    
    def generate_answers_from_existing_kb(
        self,
        questions_file: Path,
        working_dir: Path,
        output_file: Path,
        session_id: Optional[str] = None,
        resume: bool = True
    ) -> QASet:
        """
        Generate answers using an existing knowledge base.
        
        Args:
            questions_file: Path to questions JSONL file
            working_dir: Working directory containing existing knowledge base
            output_file: Path to output QA JSONL file
            session_id: Optional session ID for progress tracking
            resume: Whether to resume from existing progress (default: True)
            
        Returns:
            QASet containing generated QA pairs
            
        Raises:
            AnswerServiceError: If answer generation fails
        """
        try:
            # Create session if not provided
            if session_id is None:
                session_id = f"answer_gen_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            self.logger.info(f"Generating answers from existing knowledge base: {working_dir}")
            
            # Use existing knowledge base
            self.rag.use_existing_knowledge_base(working_dir)
            
            # Load questions
            all_questions = self._load_questions_from_file(questions_file)
            if not all_questions:
                raise AnswerServiceError(f"No questions found in {questions_file}")
            
            # Check for resume
            questions_to_process = all_questions
            existing_qa_pairs = []
            
            if resume and output_file.exists():
                try:
                    existing_qa_pairs = self._load_existing_qa_pairs(output_file)
                    processed_question_ids = {qa.question_id for qa in existing_qa_pairs}
                    questions_to_process = [q for q in all_questions if q.question_id not in processed_question_ids]
                    
                    self.logger.info(f"Resuming from {len(existing_qa_pairs)} existing QA pairs, "
                                   f"{len(questions_to_process)} questions remaining")
                    except Exception as e:
                    self.logger.warning(f"Failed to load existing progress: {e}, starting fresh")
                    questions_to_process = all_questions
                    existing_qa_pairs = []
            
            # Initialize or update progress
            if resume and self.progress_manager.get_session_progress(session_id):
                # Session exists, continue
                self.logger.info(f"Continuing existing session: {session_id}")
            else:
                # New session
            self.progress_manager.start_session(
                session_id=session_id,
                    total_items=len(all_questions),
                operation_type="answer_generation"
            )
            
                # Update progress for existing pairs
                if existing_qa_pairs:
                        self.progress_manager.update_progress(session_id, len(existing_qa_pairs))
            
            # Generate answers for remaining questions
            if questions_to_process:
                new_qa_set = self._generate_answers_batch(questions_to_process, session_id, output_file)
                new_qa_pairs = new_qa_set.qa_pairs
            else:
                new_qa_pairs = []
            
            # Combine existing and new QA pairs
            all_qa_pairs = existing_qa_pairs + new_qa_pairs
            
            # Create final QA set
                qa_set = QASet(
                document_id=session_id,
                qa_pairs=all_qa_pairs,
                created_at=datetime.now()
            )
            
            # Save final results
            if not resume or new_qa_pairs:  # Only save if not resuming or if we have new pairs
            self._save_qa_set(qa_set, output_file)
            
            # Complete session
            self.progress_manager.complete_session(session_id)
            
            self.logger.info(f"Answer generation completed: {len(qa_set.qa_pairs)} total QA pairs "
                           f"({len(existing_qa_pairs)} existing + {len(new_qa_pairs)} new)")
                return qa_set
            
        except Exception as e:
            if session_id:
                self.progress_manager.fail_session(session_id, str(e))
            error_msg = f"Failed to generate answers: {str(e)}"
            self.logger.error(error_msg)
            raise AnswerServiceError(error_msg) from e


class AnswerServiceError(Exception):
    """Custom exception for answer service errors."""
    pass 