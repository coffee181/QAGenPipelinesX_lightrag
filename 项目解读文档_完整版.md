# QAGenPipelinesX_LightRAG é¡¹ç›®å®Œæ•´è§£è¯»æ–‡æ¡£

> **ç‰ˆæœ¬**: v1.0  
> **ç”Ÿæˆæ—¶é—´**: 2025-12-23  
> **é¡¹ç›®è·¯å¾„**: D:\QAGenPipelinesX_lightrag

---

## ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
2. [ç³»ç»Ÿæ¶æ„è®¾è®¡](#2-ç³»ç»Ÿæ¶æ„è®¾è®¡)
3. [æ ¸å¿ƒæŠ€æœ¯æ ˆ](#3-æ ¸å¿ƒæŠ€æœ¯æ ˆ)
4. [è¯¦ç»†æ¨¡å—è§£è¯»](#4-è¯¦ç»†æ¨¡å—è§£è¯»)
5. [ç®—æ³•ä¸æ–¹æ³•è®º](#5-ç®—æ³•ä¸æ–¹æ³•è®º)
6. [æ ¸å¿ƒä»£ç è§£æ](#6-æ ¸å¿ƒä»£ç è§£æ)
7. [æç¤ºè¯å·¥ç¨‹](#7-æç¤ºè¯å·¥ç¨‹)
8. [æ•°æ®æµç¨‹](#8-æ•°æ®æµç¨‹)
9. [æ€§èƒ½ä¼˜åŒ–ç­–ç•¥](#9-æ€§èƒ½ä¼˜åŒ–ç­–ç•¥)
10. [ç³»ç»Ÿä¼˜åŒ–æ–¹å‘](#10-ç³»ç»Ÿä¼˜åŒ–æ–¹å‘)

---

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®å®šä½

**QAGenPipelinesX_LightRAG** æ˜¯ä¸€ä¸ªåŸºäº **LightRAGï¼ˆLight Retrieval-Augmented Generationï¼‰** æ¡†æ¶çš„ **å·¥ä¸šæŠ€æœ¯æ–‡æ¡£é—®ç­”å¯¹è‡ªåŠ¨ç”Ÿæˆç³»ç»Ÿ**ã€‚è¯¥ç³»ç»Ÿä¸“é—¨é’ˆå¯¹å·¥ä¸šé¢†åŸŸçš„æŠ€æœ¯æ–‡æ¡£ï¼ˆå¦‚æ•°æ§ç³»ç»Ÿæ‰‹å†Œã€è®¾å¤‡è¯´æ˜ä¹¦ã€å·¥è‰ºè§„èŒƒç­‰ï¼‰è¿›è¡Œæ™ºèƒ½åŒ–å¤„ç†ï¼Œè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„é—®ç­”æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°é—®ç­”ç³»ç»Ÿã€‚

### 1.2 æ ¸å¿ƒç›®æ ‡

1. **æ–‡æ¡£æ™ºèƒ½åŒ–å¤„ç†**ï¼šå°† PDF æ ¼å¼çš„æŠ€æœ¯æ–‡æ¡£è½¬æ¢ä¸ºç»“æ„åŒ–æ–‡æœ¬
2. **çŸ¥è¯†å›¾è°±æ„å»º**ï¼šåŸºäº LightRAG æ„å»ºæ–‡æ¡£çš„å®ä½“-å…³ç³»çŸ¥è¯†å›¾è°±
3. **é—®é¢˜è‡ªåŠ¨ç”Ÿæˆ**ï¼šç»“åˆçŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡ç”Ÿæˆé«˜è´¨é‡æŠ€æœ¯é—®é¢˜
4. **ç­”æ¡ˆè‡ªåŠ¨ç”Ÿæˆ**ï¼šåˆ©ç”¨ RAG æŠ€æœ¯ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢å¹¶ç”Ÿæˆç­”æ¡ˆ
5. **è´¨é‡è¯„ä¼°ä½“ç³»**ï¼šä½¿ç”¨ RAGAs æ¡†æ¶è¯„ä¼°é—®ç­”å¯¹è´¨é‡

### 1.3 åº”ç”¨åœºæ™¯

- **æŠ€æœ¯æ”¯æŒç³»ç»Ÿè®­ç»ƒæ•°æ®ç”Ÿæˆ**ï¼šä¸ºå®¢æœæœºå™¨äººæä¾›è®­ç»ƒæ•°æ®
- **çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿæ„å»º**ï¼šä¼ä¸šå†…éƒ¨æŠ€æœ¯æ–‡æ¡£é—®ç­”ç³»ç»Ÿ
- **æ–‡æ¡£æ™ºèƒ½æ£€ç´¢**ï¼šæå‡æŠ€æœ¯æ–‡æ¡£æ£€ç´¢æ•ˆç‡
- **çŸ¥è¯†ä¼ æ‰¿ä¸åŸ¹è®­**ï¼šå°†è€å¸ˆå‚…çš„ç»éªŒæ–‡æ¡£è½¬åŒ–ä¸ºå¯æŸ¥è¯¢çš„çŸ¥è¯†åº“

### 1.4 æŠ€æœ¯äº®ç‚¹

- âœ… **å®Œå…¨æœ¬åœ°åŒ–éƒ¨ç½²**ï¼šä½¿ç”¨ Ollama + DeepSeek-R1ï¼Œæ— éœ€ä¾èµ–äº‘ç«¯ API
- âœ… **çŸ¥è¯†å›¾è°±å¢å¼º**ï¼šLightRAG æä¾›å®ä½“-å…³ç³»ä¸Šä¸‹æ–‡ï¼Œæå‡é—®ç­”è´¨é‡
- âœ… **Token çº§æ–‡æœ¬åˆ‡åˆ†**ï¼šä¸ LightRAG ä¿æŒä¸€è‡´çš„åˆ‡åˆ†ç­–ç•¥ï¼ˆ1200 tokens/chunkï¼‰
- âœ… **å¹»è§‰æ£€æµ‹æœºåˆ¶**ï¼šå¤šå±‚æ¬¡ç­”æ¡ˆè´¨é‡éªŒè¯ï¼Œå‡å°‘æ¨¡å‹å¹»è§‰
- âœ… **å¢é‡ä¿å­˜ä¸æ–­ç‚¹ç»­ä¼ **ï¼šæ”¯æŒä¸­æ–­æ¢å¤ï¼Œé¿å…é‡å¤è®¡ç®—
- âœ… **å¤šæ¨¡æ€ OCR**ï¼šPaddleOCR æ”¯æŒå›¾æ–‡æ··æ’è¯†åˆ«

---

## 2. ç³»ç»Ÿæ¶æ„è®¾è®¡

### 2.1 æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      QAç”Ÿæˆç®¡é“ç³»ç»Ÿ                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
        â–¼                  â–¼                  â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ PDFå¤„ç† â”‚        â”‚ é—®é¢˜ç”Ÿæˆâ”‚        â”‚ ç­”æ¡ˆç”Ÿæˆâ”‚
   â”‚ æ¨¡å—   â”‚        â”‚ æ¨¡å—   â”‚        â”‚ æ¨¡å—   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                  â”‚                  â”‚
        â–¼                  â–¼                  â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ OCR    â”‚        â”‚ LLM    â”‚        â”‚ LightRAGâ”‚
   â”‚PaddleOCR        â”‚Ollama  â”‚        â”‚çŸ¥è¯†å›¾è°±â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                  â”‚                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ è¿›åº¦ç®¡ç† â”‚
                     â”‚ æ¨¡å—    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ¨¡å—å±‚æ¬¡ç»“æ„

```
qa_gen_pipelines/
â”œâ”€â”€ main.py                      # ä¸»å…¥å£ï¼Œå‘½ä»¤è¡Œæ¥å£
â”œâ”€â”€ config_local.yaml            # é…ç½®æ–‡ä»¶
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ services/               # ä¸šåŠ¡æœåŠ¡å±‚
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py        # PDF å¤„ç†æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ question_service.py     # é—®é¢˜ç”ŸæˆæœåŠ¡
â”‚   â”‚   â”œâ”€â”€ answer_service.py       # ç­”æ¡ˆç”ŸæˆæœåŠ¡
â”‚   â”‚   â””â”€â”€ progress_manager.py     # è¿›åº¦ç®¡ç†æœåŠ¡
â”‚   â”‚
â”‚   â”œâ”€â”€ implementations/        # æ ¸å¿ƒå®ç°å±‚
â”‚   â”‚   â”œâ”€â”€ paddle_ocr.py           # OCR å®ç°
â”‚   â”‚   â”œâ”€â”€ simple_text_chunker.py  # æ–‡æœ¬åˆ‡åˆ†å®ç°
â”‚   â”‚   â”œâ”€â”€ local_question_generator.py  # é—®é¢˜ç”Ÿæˆå®ç°
â”‚   â”‚   â”œâ”€â”€ lightrag_rag.py         # RAG å®ç°
â”‚   â”‚   â””â”€â”€ simple_markdown_processor.py # Markdown å¤„ç†
â”‚   â”‚
â”‚   â”œâ”€â”€ interfaces/             # æ¥å£å®šä¹‰å±‚
â”‚   â”‚   â”œâ”€â”€ ocr_interface.py
â”‚   â”‚   â”œâ”€â”€ text_chunker_interface.py
â”‚   â”‚   â”œâ”€â”€ question_generator_interface.py
â”‚   â”‚   â””â”€â”€ rag_interface.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # æ•°æ®æ¨¡å‹å±‚
â”‚   â”‚   â”œâ”€â”€ document.py             # æ–‡æ¡£æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ question.py             # é—®é¢˜æ¨¡å‹
â”‚   â”‚   â””â”€â”€ qa_pair.py              # é—®ç­”å¯¹æ¨¡å‹
â”‚   â”‚
â”‚   â””â”€â”€ utils/                  # å·¥å…·å±‚
â”‚       â”œâ”€â”€ config.py               # é…ç½®ç®¡ç†
â”‚       â”œâ”€â”€ lightrag_utils.py       # LightRAG å·¥å…·
â”‚       â”œâ”€â”€ chunk_repository.py     # Chunk æŒä¹…åŒ–
â”‚       â””â”€â”€ progress_display.py     # è¿›åº¦æ˜¾ç¤º
â”‚
â””â”€â”€ evaluation/                 # è¯„ä¼°æ¨¡å—
    â””â”€â”€ ragas_evaluate.py           # RAGAs è¯„ä¼°å·¥å…·
```

### 2.3 æ ¸å¿ƒç»„ä»¶è¯´æ˜

| ç»„ä»¶åç§° | åŠŸèƒ½æè¿° | å…³é”®æŠ€æœ¯ |
|---------|---------|---------|
| **PDFProcessor** | PDF æ–‡æ¡£å¤„ç† | PaddleOCR PPStructureV3 |
| **SimpleTextChunker** | æ–‡æœ¬åˆ‡åˆ† | Token-based Chunking, tiktoken |
| **LocalQuestionGenerator** | é—®é¢˜ç”Ÿæˆ | DeepSeek-R1, çŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡ |
| **LightRAGImplementation** | RAG æ£€ç´¢ä¸ç­”æ¡ˆç”Ÿæˆ | LightRAG, çŸ¥è¯†å›¾è°± |
| **AnswerService** | ç­”æ¡ˆç”Ÿæˆä¸è´¨é‡æ§åˆ¶ | å¹»è§‰æ£€æµ‹, å¢é‡ä¿å­˜ |
| **ProgressManager** | è¿›åº¦è·Ÿè¸ª | JSONL æŒä¹…åŒ–, æ–­ç‚¹ç»­ä¼  |

---

## 3. æ ¸å¿ƒæŠ€æœ¯æ ˆ

### 3.1 æ¡†æ¶ä¸åº“

#### 3.1.1 æ ¸å¿ƒæ¡†æ¶
- **LightRAG**: è½»é‡çº§ RAG æ¡†æ¶ï¼Œæ”¯æŒçŸ¥è¯†å›¾è°±æ„å»ºä¸æ£€ç´¢
- **Ollama**: æœ¬åœ°å¤§æ¨¡å‹æ¨ç†æ¡†æ¶ï¼Œæ”¯æŒ DeepSeek-R1ã€BGE-M3 ç­‰æ¨¡å‹
- **PaddleOCR**: ç™¾åº¦é£æ¡¨ OCR å¼•æ“ï¼Œæ”¯æŒä¸­è‹±æ–‡æ··åˆè¯†åˆ«

#### 3.1.2 å¤§è¯­è¨€æ¨¡å‹
- **DeepSeek-R1:32b**: ä¸»åŠ›æ¨¡å‹ï¼Œç”¨äºé—®é¢˜ç”Ÿæˆã€ç­”æ¡ˆç”Ÿæˆã€å®ä½“æŠ½å–
- **BGE-M3**: åµŒå…¥æ¨¡å‹ï¼ˆ1024ç»´ï¼‰ï¼Œç”¨äºå‘é‡åŒ–æ–‡æœ¬ã€ç›¸ä¼¼åº¦è®¡ç®—

#### 3.1.3 æ•°æ®å¤„ç†
- **tiktoken**: OpenAI çš„ tokenizerï¼Œç”¨äº token çº§åˆ‡åˆ†
- **jsonlines**: JSONL æ ¼å¼æ•°æ®è¯»å†™
- **pydantic**: æ•°æ®æ¨¡å‹éªŒè¯

#### 3.1.4 è¯„ä¼°æ¡†æ¶
- **RAGAs**: RAG ç³»ç»Ÿè¯„ä¼°æ¡†æ¶ï¼Œæ”¯æŒå¤šç»´åº¦æŒ‡æ ‡
  - Faithfulness (å¿ å®åº¦)
  - Answer Relevancy (ç­”æ¡ˆç›¸å…³æ€§)
  - Context Precision (ä¸Šä¸‹æ–‡ç²¾ç¡®åº¦)
  - Context Recall (ä¸Šä¸‹æ–‡å¬å›ç‡)
  - Answer Correctness (ç­”æ¡ˆæ­£ç¡®æ€§)

### 3.2 å…³é”®æŠ€æœ¯é€‰å‹åŸå› 

| æŠ€æœ¯ | é€‰æ‹©åŸå›  |
|-----|---------|
| **DeepSeek-R1** | 1. 32B å‚æ•°ï¼Œæ¨ç†èƒ½åŠ›å¼ºï¼›2. æ”¯æŒ <think> æ ‡ç­¾ï¼Œå¯è§‚å¯Ÿæ¨ç†è¿‡ç¨‹ï¼›3. ä¸­è‹±æ–‡æ”¯æŒè‰¯å¥½ |
| **LightRAG** | 1. è½»é‡çº§ï¼Œæ˜“äºé›†æˆï¼›2. è‡ªåŠ¨æ„å»ºçŸ¥è¯†å›¾è°±ï¼›3. æ”¯æŒå¤šç§æ£€ç´¢æ¨¡å¼ï¼ˆmix/naive/localï¼‰ |
| **Ollama** | 1. å®Œå…¨æœ¬åœ°åŒ–ï¼Œæ•°æ®éšç§å®‰å…¨ï¼›2. èµ„æºå ç”¨å¯æ§ï¼›3. æ”¯æŒå¤šæ¨¡å‹åˆ‡æ¢ |
| **PaddleOCR** | 1. ä¸­æ–‡è¯†åˆ«ç²¾åº¦é«˜ï¼›2. æ”¯æŒè¡¨æ ¼ç»“æ„è¯†åˆ«ï¼›3. å¼€æºå…è´¹ |
| **Token-based Chunking** | 1. ä¸ LLM token é™åˆ¶å¯¹é½ï¼›2. é¿å…å¥å­æˆªæ–­ï¼›3. ä¸ LightRAG ä¿æŒä¸€è‡´ |

---

## 4. è¯¦ç»†æ¨¡å—è§£è¯»

### 4.1 PDF å¤„ç†æ¨¡å— (`PDFProcessor`)

#### 4.1.1 åŠŸèƒ½èŒè´£
- å°† PDF æ–‡æ¡£è½¬æ¢ä¸ºç»“æ„åŒ–æ–‡æœ¬ï¼ˆMarkdown æ ¼å¼ï¼‰
- è¯†åˆ«å¹¶ä¿å­˜æ–‡æ¡£ä¸­çš„å›¾ç‰‡
- æ”¯æŒæ‰¹é‡å¤„ç†ä¸æ–­ç‚¹ç»­ä¼ 

#### 4.1.2 æ ¸å¿ƒæµç¨‹

```python
def process_single_pdf(self, pdf_path: Path, session_id: Optional[str] = None):
    """
    å¤„ç†å•ä¸ª PDF æ–‡ä»¶
    
    æµç¨‹:
    1. éªŒè¯æ–‡ä»¶æ ¼å¼ (is_supported_format)
    2. OCR æ–‡å­—æå– (process_pdf_to_document)
    3. ä¿å­˜æå–æ–‡æœ¬ (save_text_file)
    4. æ›´æ–°è¿›åº¦ç®¡ç† (update_session_progress)
    """
```

#### 4.1.3 å…³é”®æŠ€æœ¯ç‚¹

**1. PaddleOCR PPStructureV3 é…ç½®**
```yaml
ocr:
  provider: "paddle"
  paddle:
    lang: "ch"           # ä¸­æ–‡æ¨¡å‹
    use_angle_cls: true  # å¯ç”¨è§’åº¦åˆ†ç±»
    dpi: 300             # å›¾åƒDPI
```

**2. OCR è¾“å‡ºæ ¼å¼**
- é¡µé¢æ ‡è®°ï¼š`--- Page {page_num} ---`
- ä¿ç•™åŸå§‹æ ¼å¼ï¼šæ¢è¡Œç¬¦ã€ç©ºæ ¼ã€è¡¨æ ¼ç»“æ„
- å›¾ç‰‡ä¿å­˜ï¼š`{document_name}_imgs/{page}_{idx}.jpg`

**3. æ€§èƒ½ç»Ÿè®¡**
```python
stats = {
    "ocr_time": "æ–‡å­—æå–è€—æ—¶",
    "text_length": "æå–æ–‡æœ¬é•¿åº¦",
    "total_time": "æ€»å¤„ç†æ—¶é—´"
}
```

### 4.2 æ–‡æœ¬åˆ‡åˆ†æ¨¡å— (`SimpleTextChunker`)

#### 4.2.1 åˆ‡åˆ†ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|-----|------|------|---------|
| **Token-based** | ä¸ LLM å¯¹é½ï¼Œé¿å…è¶…é•¿ | éœ€è¦ tokenizer | ğŸŒŸ æ¨èç”¨äº RAG ç³»ç»Ÿ |
| **Sentence-based** | è¯­ä¹‰å®Œæ•´æ€§å¥½ | å¯èƒ½è¶…è¿‡ token é™åˆ¶ | çŸ­æ–‡æœ¬åˆ‡åˆ† |
| **Character-based** | å®ç°ç®€å• | å¯èƒ½æˆªæ–­å¥å­ | ç²—ç²’åº¦åˆ‡åˆ† |

#### 4.2.2 Token-based Chunking å®ç°

**æ ¸å¿ƒå‚æ•°**ï¼ˆä¸ LightRAG é»˜è®¤å€¼ä¸€è‡´ï¼‰ï¼š
```yaml
text_chunker:
  use_token_chunking: true
  tokenizer_model: "cl100k_base"   # GPT-3.5/4 tokenizer
  chunk_token_size: 1200            # æ¯ä¸ª chunk 1200 tokens
  chunk_overlap_token_size: 100     # é‡å  100 tokens
```

**åˆ‡åˆ†ç®—æ³•**ï¼š
```python
def _chunk_by_tokens(self, text: str, document_id: str):
    """
    ä½¿ç”¨ LightRAG çš„ chunking_by_token_size å‡½æ•°
    
    1. ç¼–ç æ–‡æœ¬ä¸º tokens
    2. æŒ‰ chunk_token_size åˆ‡åˆ†
    3. æ·»åŠ  chunk_overlap_token_size é‡å 
    4. è®¡ç®— LightRAG å…¼å®¹çš„ chunk_id
    """
    chunk_dicts = chunking_by_token_size(
        tokenizer=self.tokenizer,
        content=text,
        overlap_token_size=100,
        max_token_size=1200
    )
    
    for chunk_dict in chunk_dicts:
        chunk_id = compute_lightrag_chunk_id(content)  # MD5 hash
        # chunk_id æ ¼å¼: "chunk-{md5_hash}"
```

**é‡å ç­–ç•¥ç¤ºæ„å›¾**ï¼š
```
Chunk 1: [------ 1200 tokens ------]
                       [overlap 100]
Chunk 2:               [------ 1200 tokens ------]
                                      [overlap 100]
Chunk 3:                              [------ 1200 tokens ------]
```

#### 4.2.3 Chunk ID è®¡ç®—

**LightRAG å…¼å®¹æ€§**ï¼š
```python
def compute_lightrag_chunk_id(content: str) -> str:
    """
    LightRAG çš„ chunk_id è®¡ç®—è§„åˆ™:
    1. æ¸…ç†æ–‡æœ¬ (å»ç©ºæ ¼ã€ç©ºå­—èŠ‚)
    2. è®¡ç®— MD5 hash
    3. æ·»åŠ å‰ç¼€ "chunk-"
    """
    cleaned = content.strip().replace("\x00", "")
    return "chunk-" + hashlib.md5(cleaned.encode("utf-8")).hexdigest()
```

**ç¤ºä¾‹**ï¼š
```
åŸå§‹æ–‡æœ¬: "GSK988TA ä¸»è½´æœ€é«˜ 8000 r/min..."
chunk_id: "chunk-a3f5e8d9c2b1..."
```

### 4.3 é—®é¢˜ç”Ÿæˆæ¨¡å— (`LocalQuestionGenerator`)

#### 4.3.1 æ•´ä½“æµç¨‹

```
è¾“å…¥: DocumentChunk (æ–‡æœ¬å—)
  â†“
1. æ„å»ºçŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡ (_build_context_for_chunk)
   - æ£€ç´¢ç›¸å…³å®ä½“ (max_context_entities=5)
   - æ£€ç´¢ç›¸å…³å…³ç³» (max_context_relations=5)
   - è·å–ç›¸å…³ chunk ç‰‡æ®µ (max_context_snippets=2)
  â†“
2. ç»„è£…æç¤ºè¯ (_compose_prompt_text)
   - system_prompt: å®šä¹‰ä»»åŠ¡ç›®æ ‡
   - human_prompt: åŒ…å« <chunk> å’Œ <knowledge_graph> ä¸Šä¸‹æ–‡
  â†“
3. è°ƒç”¨ Ollama API (_call_ollama_api)
   - æ¨¡å‹: DeepSeek-R1:32b
   - æ¸©åº¦: 0.7
   - max_tokens: 2048
  â†“
4. è§£æå“åº” (parse_questions_from_response)
   - æ¸…ç† <think> æ ‡ç­¾
   - æå–é—®é¢˜ (æ­£åˆ™åŒ¹é…)
   - éªŒè¯é—®é¢˜è´¨é‡
  â†“
è¾“å‡º: List[Question]
```

#### 4.3.2 çŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡æ„å»º

**LightRAGContextBuilder æ ¸å¿ƒé€»è¾‘**ï¼š
```python
def build_context(self, chunk_id: str) -> Dict[str, Any]:
    """
    ä» LightRAG çŸ¥è¯†å›¾è°±ä¸­æ£€ç´¢ä¸Šä¸‹æ–‡
    
    1. æ ¹æ® chunk_id æŸ¥è¯¢ç›¸å…³èŠ‚ç‚¹ (å®ä½“)
    2. æ ¹æ® chunk_id æŸ¥è¯¢ç›¸å…³è¾¹ (å…³ç³»)
    3. æå–å®ä½“æè¿°ã€å…³ç³»æè¿°
    4. è·å–ç›¸å…³ chunk çš„æ–‡æœ¬ç‰‡æ®µ
    """
    nodes = graph.get_nodes_by_chunk_ids([chunk_id])
    edges = graph.get_edges_by_chunk_ids([chunk_id])
    
    # æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
    context = f"""
    ã€ç›¸å…³å®ä½“ä¿¡æ¯ã€‘
    - å®ä½“ GSK988TA (ç±»å‹: è®¾å¤‡): æ•°æ§ç³»ç»Ÿå‹å·
    - å®ä½“ ä¸»è½´ç³»ç»Ÿ (ç±»å‹: ç»„ä»¶): æœºåºŠæ ¸å¿ƒéƒ¨ä»¶
    
    ã€ç›¸å…³å…³ç³»ä¿¡æ¯ã€‘
    - GSK988TA â†” ä¸»è½´ç³»ç»Ÿ: ä½¿ç”¨å…³ç³»ï¼Œæœ€é«˜è½¬é€Ÿ8000 r/min
    
    ã€çŸ¥è¯†å›¾è°±ç‰‡æ®µã€‘
    - ç‰‡æ®µ chunk-xxx: å…è®¸åˆ€å…·æœ€å¤§é‡é‡ 7 kg
    """
    
    return {
        "prompt_context": context,
        "related_entities": ["GSK988TA", "ä¸»è½´ç³»ç»Ÿ"],
        "related_chunk_ids": ["chunk-xxx", "chunk-yyy"]
    }
```

**é…ç½®å‚æ•°**ï¼š
```yaml
question_generator:
  local:
    enable_kg_context: true       # å¯ç”¨çŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡
    max_context_entities: 5       # æœ€å¤šæå– 5 ä¸ªå®ä½“
    max_context_relations: 5      # æœ€å¤šæå– 5 ä¸ªå…³ç³»
    max_context_snippets: 2       # æœ€å¤šæå– 2 ä¸ªç›¸å…³ chunk ç‰‡æ®µ
    context_snippet_chars: 200    # æ¯ä¸ªç‰‡æ®µ 200 å­—ç¬¦
    max_related_chunk_ids: 10     # æœ€å¤šå…³è” 10 ä¸ª chunk_id
```

#### 4.3.3 é—®é¢˜è§£æä¸éªŒè¯

**è§£æç­–ç•¥ï¼ˆå¤šæ ¼å¼å…¼å®¹ï¼‰**ï¼š
```python
# æ ¼å¼1: æ–°æ ¼å¼
é—®é¢˜1: GSK988TA çš„ä¸»è½´æœ€é«˜è½¬é€Ÿæ˜¯å¤šå°‘ï¼Ÿ
é—®é¢˜2: å¦‚ä½•ç»´æŠ¤ 8000 r/min çš„ä¸»è½´ç³»ç»Ÿï¼Ÿ

# æ ¼å¼2: æ—§æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
é—®ç­”å¯¹1:
é—®é¢˜: GSK988TA çš„ä¸»è½´æœ€é«˜è½¬é€Ÿæ˜¯å¤šå°‘ï¼Ÿ
ç­”æ¡ˆ: 8000 r/min

# æ ¼å¼3: Fallbackï¼ˆé€è¡Œæ£€æµ‹ï¼‰
å¦‚ä½•ç»´æŠ¤ 8000 r/min çš„ä¸»è½´ç³»ç»Ÿï¼Ÿ
GSK988TA æ”¯æŒå“ªäº›åˆ€å…·ï¼Ÿ
```

**è´¨é‡éªŒè¯è§„åˆ™**ï¼š
```python
is_valid = (
    len(question_content) > 15 and              # é•¿åº¦ > 15 å­—ç¬¦
    ("ï¼Ÿ" in question_content or "?" in question_content) and  # åŒ…å«é—®å·
    "ç­”æ¡ˆ" not in question_content and          # ä¸åŒ…å«"ç­”æ¡ˆ"
    "è§£ç­”" not in question_content and          # ä¸åŒ…å«"è§£ç­”"
    "Answer" not in question_content            # ä¸åŒ…å«"Answer"
)
```

#### 4.3.4 å®ä½“æå–

**å€™é€‰å®ä½“æ¨¡å¼**ï¼š
```python
patterns = [
    r"[A-Z]{2,}\d+[A-Z]*",      # GSK988TA, VMC850L
    r"[A-Z]+\d+[A-Z0-9]*",      # DMC500P
    r"[A-Z][A-Za-z0-9\-]{2,}",  # BRH-300
]
```

**ç¤ºä¾‹**ï¼š
```python
è¾“å…¥é—®é¢˜: "GSK988TA çš„ X/Y/Z è¡Œç¨‹ 800/500/500 mm å¦‚ä½•ç»´æŠ¤ï¼Ÿ"
æå–å®ä½“: ["GSK988TA", "X", "Y", "Z"]
```

### 4.4 ç­”æ¡ˆç”Ÿæˆæ¨¡å— (`AnswerService`)

#### 4.4.1 æ ¸å¿ƒæµç¨‹

```
è¾“å…¥: Question
  â†“
1. åŠ è½½å±€éƒ¨æ£€ç´¢èŒƒå›´ (_load_local_scope)
   - è¯»å–é—®é¢˜ç”Ÿæˆé˜¶æ®µä¿å­˜çš„ scope.json
   - åŒ…å« primary_chunk_ids, related_chunk_ids, related_entities
  â†“
2. RAG æ£€ç´¢ (LightRAG.query_single_question)
   - æ¨¡å¼: mix (å‘é‡ + çŸ¥è¯†å›¾è°±æ··åˆ)
   - è¶…æ—¶: 1200 ç§’
   - é‡è¯•: æœ€å¤š 2 æ¬¡
  â†“
3. ç­”æ¡ˆè´¨é‡éªŒè¯ (_verify_answer_authenticity)
   - å¹»è§‰æ£€æµ‹: æ£€æŸ¥æ˜¯å¦å¼•å…¥æ–°å®ä½“/æ–°æ•°å€¼
   - ç­”æ¡ˆåˆ†ç±»: valid_positive / valid_negative / invalid_no_info / invalid_error
  â†“
4. ç­”æ¡ˆæ¸…ç† (markdown_processor.clean_llm_response)
   - æ¸…ç† <think> æ ‡ç­¾
   - ç§»é™¤å¤šä½™ç©ºè¡Œ
  â†“
5. å¢é‡ä¿å­˜ (_incremental_save)
   - æ¯ 5 ä¸ª QA å¯¹ä¿å­˜ä¸€æ¬¡
   - æ”¯æŒä¸­æ–­æ¢å¤
  â†“
è¾“å‡º: QAPair
```

#### 4.4.2 æ–‡æ¡£éš”ç¦»ç­–ç•¥

**é—®é¢˜**ï¼šå¤šä¸ªæ–‡æ¡£å…±äº«ä¸€ä¸ªçŸ¥è¯†åº“æ—¶ï¼Œæ£€ç´¢å¯èƒ½è·¨æ–‡æ¡£æ±¡æŸ“ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
def query_single_question(
    self,
    question: str,
    source_document: Optional[str] = None,  # æŒ‡å®šæ¥æºæ–‡æ¡£
    allowed_chunk_ids: Optional[List[str]] = None  # é™åˆ¶æ£€ç´¢èŒƒå›´
):
    """
    é™åˆ¶æ£€ç´¢èŒƒå›´ï¼Œç¡®ä¿ç­”æ¡ˆæ¥è‡ªæŒ‡å®šæ–‡æ¡£
    
    allowed_chunk_ids æ¥æº:
    1. Question.metadata['lightrag_chunk_id']  # ä¸» chunk
    2. Question.metadata['related_chunk_ids']  # å…³è” chunks
    3. local_scope/{document_id}_scope.json    # å±€éƒ¨èŒƒå›´
    """
```

**å±€éƒ¨èŒƒå›´ç¤ºä¾‹** (`{document_id}_scope.json`):
```json
{
  "document_id": "GSK 27ié«˜ç«¯å¤šé€šé“æ•°æ§ç³»ç»Ÿ 20250226",
  "primary_chunk_ids": ["chunk-a3f5e8d9...", "chunk-b2c4d6f8..."],
  "related_chunk_ids": ["chunk-c5e7g9h1...", "chunk-d6f8h0j2..."],
  "related_entities": ["GSK27i", "ä¸»è½´ç³»ç»Ÿ", "åˆ€åº“"],
  "generated_at": "2025-12-23T10:30:00"
}
```

#### 4.4.3 å¹»è§‰æ£€æµ‹æœºåˆ¶

**æ£€æµ‹ç­–ç•¥**ï¼š
```python
def _verify_answer_authenticity(self, question: str, answer: str) -> bool:
    """
    å¤šå±‚æ¬¡å¹»è§‰æ£€æµ‹
    
    1. å‹å·æ£€æµ‹: ç­”æ¡ˆæ˜¯å¦å¼•å…¥é—®é¢˜ä¸­æœªæåŠçš„å‹å·ï¼Ÿ
       é—®é¢˜: "GSK988TA çš„è½¬é€Ÿæ˜¯å¤šå°‘ï¼Ÿ"
       ç­”æ¡ˆ: "GSK988TA æœ€é«˜ 8000 r/min, è€Œ GSK27i æœ€é«˜ 12000 r/min"
       âŒ å¼•å…¥äº†æ–°å‹å· GSK27iï¼Œå¯èƒ½æ˜¯å¹»è§‰
    
    2. æ•°å€¼æ£€æµ‹: ç­”æ¡ˆä¸­çš„æ•°å€¼æ˜¯å¦ä¸é—®é¢˜ä¸ä¸€è‡´ï¼Ÿ
       é—®é¢˜: "X/Y/Z è¡Œç¨‹ 800/500/500 mm å¦‚ä½•ç»´æŠ¤ï¼Ÿ"
       ç­”æ¡ˆ: "X/Y/Z è¡Œç¨‹ 1000/600/600 mm éœ€è¦æ¯æœˆä¿å…»"
       âŒ æ•°å€¼ä¸ä¸€è‡´ï¼Œå¯èƒ½æ˜¯å¹»è§‰
    
    3. å•ä½æ£€æµ‹: æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦åŒ…å«æŠ€æœ¯å‚æ•°ä½†æ•°å€¼ä¸åŒ¹é…
       (mm, rpm, MPa, kW, kg, Â°C, Hz)
    """
    question_models = set(re.findall(r'[A-Z]{2,}\d+[A-Z]*', question))
    answer_models = set(re.findall(r'[A-Z]{2,}\d+[A-Z]*', answer))
    new_models = answer_models - question_models
    
    if new_models:
        logger.warning(f"æ£€æµ‹åˆ°å¹»è§‰: ç­”æ¡ˆå¼•å…¥æ–°å‹å· {new_models}")
        return False
    
    return True
```

#### 4.4.4 ç­”æ¡ˆç±»å‹åˆ†ç±»

**AnswerType æšä¸¾**ï¼š
```python
class AnswerType(Enum):
    VALID_POSITIVE = "valid_positive"      # æœ‰æ•ˆçš„æ­£é¢ç­”æ¡ˆ
    VALID_NEGATIVE = "valid_negative"      # æœ‰æ•ˆçš„å¦å®šç­”æ¡ˆ ("ä¸æ”¯æŒXXåŠŸèƒ½")
    INVALID_NO_INFO = "invalid_no_info"    # æ— æ•ˆ("æ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯")
    INVALID_ERROR = "invalid_error"        # é”™è¯¯ä¿¡æ¯
```

**åˆ†ç±»é€»è¾‘**ï¼š
```python
def _classify_answer_type(self, answer: str) -> AnswerType:
    # 1. æŠ€æœ¯æ€§å¦å®šç­”æ¡ˆ (ä¿ç•™)
    if "ä¸æ”¯æŒ" in answer or "ä¸å…·å¤‡" in answer:
        if len(answer) > 30:  # ç»™å‡ºå…·ä½“è¯´æ˜
            return VALID_NEGATIVE  # âœ… æœ‰æ•ˆ
    
    # 2. æ— ä¿¡æ¯ç­”æ¡ˆ (ä¸¢å¼ƒ)
    if "æ— æ³•æ‰¾åˆ°" in answer or "æ²¡æœ‰ç›¸å…³ä¿¡æ¯" in answer:
        return INVALID_NO_INFO  # âŒ æ— æ•ˆ
    
    # 3. çŸ­ç­”æ¡ˆéªŒè¯
    if len(answer) < 50:
        has_technical_content = (
            bool(re.search(r'\d', answer)) or  # åŒ…å«æ•°å­—
            bool(re.search(r'(mm|rpm|MPa)', answer))  # åŒ…å«å•ä½
        )
        if not has_technical_content:
            return INVALID_ERROR  # âŒ æ— æ•ˆ
    
    # 4. é»˜è®¤ä¸ºæœ‰æ•ˆç­”æ¡ˆ
    return VALID_POSITIVE  # âœ… æœ‰æ•ˆ
```

#### 4.4.5 å¢é‡ä¿å­˜ä¸æ–­ç‚¹ç»­ä¼ 

**å¢é‡ä¿å­˜**ï¼š
```python
def _generate_answers_batch(self, questions: List[Question], ...):
    """
    æ¯å¤„ç† 5 ä¸ª QA å¯¹ä¿å­˜ä¸€æ¬¡
    """
    self._save_interval = 5
    
    for i, question in enumerate(questions):
        qa_pair = generate_qa_pair(question)
        self._current_qa_pairs.append(qa_pair)
        
        # å¢é‡ä¿å­˜
        if (i + 1) % self._save_interval == 0:
            self._incremental_save()
```

**æ–­ç‚¹ç»­ä¼ **ï¼š
```python
def generate_answers_from_existing_kb(
    self,
    questions_file: Path,
    output_file: Path,
    resume: bool = True
):
    """
    æ”¯æŒæ¢å¤è¿›åº¦
    """
    if resume and output_file.exists():
        # åŠ è½½å·²ç”Ÿæˆçš„ QA å¯¹
        existing_qa_pairs = self._load_existing_qa_pairs(output_file)
        processed_question_ids = {qa.question_id for qa in existing_qa_pairs}
        
        # è¿‡æ»¤å·²å¤„ç†çš„é—®é¢˜
        questions_to_process = [
            q for q in all_questions
            if q.question_id not in processed_question_ids
        ]
```

---

## 5. ç®—æ³•ä¸æ–¹æ³•è®º

### 5.1 çŸ¥è¯†å›¾è°±æ„å»º (LightRAG)

#### 5.1.1 å®ä½“æŠ½å–ç®—æ³•

**Prompt æ¨¡æ¿**ï¼ˆLightRAG å†…ç½®ï¼‰ï¼š
```
ä½ æ˜¯ä¸€ä¸ªå®ä½“æŠ½å–ä¸“å®¶ã€‚ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æŠ½å–æ‰€æœ‰é‡è¦å®ä½“ï¼ŒåŒ…æ‹¬ï¼š
- è®¾å¤‡å‹å·
- ç»„ä»¶åç§°
- æŠ€æœ¯å‚æ•°
- æ“ä½œæ­¥éª¤

æ–‡æœ¬: {chunk_content}

è¾“å‡ºæ ¼å¼:
å®ä½“1: GSK988TA, ç±»å‹: è®¾å¤‡, æè¿°: æ•°æ§ç³»ç»Ÿå‹å·
å®ä½“2: ä¸»è½´ç³»ç»Ÿ, ç±»å‹: ç»„ä»¶, æè¿°: æœºåºŠæ ¸å¿ƒéƒ¨ä»¶
...
```

**å®ä½“å­˜å‚¨æ ¼å¼**ï¼ˆLightRAGï¼‰ï¼š
```json
{
  "entity_id": "GSK988TA",
  "entity_name": "GSK988TA",
  "entity_type": "è®¾å¤‡",
  "description": "æ•°æ§ç³»ç»Ÿå‹å·ï¼Œæœ€é«˜è½¬é€Ÿ8000 r/min",
  "source_id": "chunk-a3f5e8d9...",
  "tokens": 128
}
```

#### 5.1.2 å…³ç³»æŠ½å–ç®—æ³•

**Prompt æ¨¡æ¿**ï¼ˆLightRAG å†…ç½®ï¼‰ï¼š
```
ä»ä»¥ä¸‹å®ä½“ä¸­è¯†åˆ«å…³ç³»:

å®ä½“åˆ—è¡¨: GSK988TA, ä¸»è½´ç³»ç»Ÿ, åˆ€åº“

è¾“å‡ºæ ¼å¼:
å…³ç³»1: GSK988TA -ä½¿ç”¨-> ä¸»è½´ç³»ç»Ÿ, æè¿°: æœ€é«˜è½¬é€Ÿ8000 r/min
å…³ç³»2: GSK988TA -é…å¤‡-> åˆ€åº“, æè¿°: 24æŠŠåˆ€å…·
...
```

**å…³ç³»å­˜å‚¨æ ¼å¼**ï¼ˆLightRAGï¼‰ï¼š
```json
{
  "src_id": "GSK988TA",
  "tgt_id": "ä¸»è½´ç³»ç»Ÿ",
  "description": "ä½¿ç”¨å…³ç³»ï¼Œæœ€é«˜è½¬é€Ÿ8000 r/min",
  "keywords": ["è½¬é€Ÿ", "8000 r/min"],
  "source_id": "chunk-a3f5e8d9..."
}
```

#### 5.1.3 çŸ¥è¯†å›¾è°±å­˜å‚¨

**å­˜å‚¨ç»“æ„**ï¼ˆGraphML + JSONï¼‰ï¼š
```
working/vectorized/
â”œâ”€â”€ graph_chunk_entity_relation.graphml    # å›¾ç»“æ„ (Neo4j å¯å¯¼å…¥)
â”œâ”€â”€ kv_store_full_entities.json            # å®ä½“è¯¦æƒ…
â”œâ”€â”€ kv_store_full_relations.json           # å…³ç³»è¯¦æƒ…
â”œâ”€â”€ kv_store_text_chunks.json              # Chunk è¯¦æƒ…
â”œâ”€â”€ vdb_entities.json                      # å®ä½“å‘é‡
â”œâ”€â”€ vdb_relationships.json                 # å…³ç³»å‘é‡
â””â”€â”€ vdb_chunks.json                        # Chunk å‘é‡
```

**å‘é‡åŒ–æ¨¡å‹**ï¼š
- æ¨¡å‹: `bge-m3:latest` (BGE-M3, 1024ç»´)
- æä¾›æ–¹: Ollama
- ç”¨é€”: å®ä½“/å…³ç³»/chunk çš„å‘é‡æ£€ç´¢

### 5.2 é—®é¢˜ç”Ÿæˆç­–ç•¥

#### 5.2.1 é—®é¢˜åˆ†å¸ƒç­–ç•¥

**é…ç½®ç›®æ ‡**ï¼š
```yaml
prompts:
  human_prompt: |
    ç”Ÿæˆ {questions_per_chunk} ä¸ªé—®é¢˜ï¼Œæ»¡è¶³åˆ†å¸ƒè¦æ±‚ï¼š
    - åŸºç¡€å‚æ•°ç±»ï¼ˆâ‰¥60%ï¼‰ï¼šå•ä¸€å®ä½“çš„å‚æ•°ã€æ¥å£ã€é‡ç¨‹
    - è¿›é˜¶å…³è”ç±»ï¼ˆâ‰¤40%ï¼‰ï¼šæ¡ä»¶ã€çº¦æŸã€å¯¹æ¯”ã€å¼‚å¸¸ã€æ“ä½œæ­¥éª¤
```

**ç¤ºä¾‹**ï¼š
```
# åŸºç¡€å‚æ•°ç±» (60%)
é—®é¢˜1: GSK988TA çš„ä¸»è½´æœ€é«˜è½¬é€Ÿæ˜¯å¤šå°‘ï¼Ÿ
é—®é¢˜2: X/Y/Z è¡Œç¨‹åˆ†åˆ«æ˜¯å¤šå°‘ï¼Ÿ
é—®é¢˜3: å®šä½ç²¾åº¦æ˜¯å¤šå°‘ï¼Ÿ
é—®é¢˜4: é‡å¤å®šä½ç²¾åº¦æ˜¯å¤šå°‘ï¼Ÿ
é—®é¢˜5: åˆ€åº“å®¹é‡æ˜¯å¤šå°‘ï¼Ÿ
é—®é¢˜6: å…è®¸åˆ€å…·æœ€å¤§é‡é‡æ˜¯å¤šå°‘ï¼Ÿ

# è¿›é˜¶å…³è”ç±» (40%)
é—®é¢˜7: åœ¨ä¸»è½´ 8000 r/min è¿è¡Œæ—¶ï¼Œå¤–å–·ä¸ä¸­å¿ƒå†·å´åº”å¦‚ä½•åˆ‡æ¢ï¼Ÿ
é—®é¢˜8: X/Y/Z è¡Œç¨‹ 800/500/500 mm å¯¹å®šä½ç²¾åº¦çš„ç»´ä¿ç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿ
é—®é¢˜9: 24 æŠŠåˆ€åº“åœ¨åˆ€å…·é‡é‡ä¸Šé™ 7 kg æ—¶ï¼Œé«˜é€Ÿæ¢åˆ€éœ€è¦å“ªäº›å¹³è¡¡æ­¥éª¤ï¼Ÿ
é—®é¢˜10: å¦‚ä½•æ ¡éªŒå®šä½ç²¾åº¦ Â±0.01 mm ä¸é‡å¤å®šä½ Â±0.005 mmï¼Ÿ
```

#### 5.2.2 é—®é¢˜è´¨é‡æ§åˆ¶

**ç¡¬æ€§çº¦æŸ**ï¼š
```yaml
prompts:
  human_prompt: |
    å…³é”®ç¡¬æ€§çº¦æŸï¼ˆåŠ¡å¿…éµå®ˆï¼‰ï¼š
    - æ¯ä¸ªé—®é¢˜å¿…é¡»åŒ…å« chunk æˆ– knowledge_graph ä¸­çš„å®ä½“/å‹å·/æ•°å­—
    - ç¦æ­¢ä½¿ç”¨"è¿™å°/è¯¥/æ­¤/è¿™ä¸ª"ç­‰ä»£è¯ï¼Œå¿…é¡»ç‚¹åå…·ä½“å¯¹è±¡
    - è‹¥ä¸Šä¸‹æ–‡ç¼ºå°‘å¯ç”¨å®ä½“/æ•°å­—ï¼Œè¯·å°‘ç”Ÿæˆæˆ–è¿”å›ç©º
    - åªè¾“å‡ºé—®é¢˜ï¼Œä¸è¦è¾“å‡ºç­”æ¡ˆ
```

**è´¨é‡è¿‡æ»¤**ï¼ˆé…ç½®é¡¹ï¼‰ï¼š
```yaml
question_generator:
  enable_deduplication: true           # å¯ç”¨é—®é¢˜å»é‡
  dedup_similarity_threshold: 0.85     # å»é‡ç›¸ä¼¼åº¦é˜ˆå€¼
  enable_quality_filter: true          # å¯ç”¨è´¨é‡è¿‡æ»¤
```

### 5.3 ç­”æ¡ˆç”Ÿæˆç­–ç•¥

#### 5.3.1 LightRAG æ£€ç´¢æ¨¡å¼

**Mix æ¨¡å¼**ï¼ˆæ¨èï¼‰ï¼š
```python
query_param = QueryParam(
    mode="mix",  # å‘é‡æ£€ç´¢ + çŸ¥è¯†å›¾è°±æ··åˆ
    top_k=20,                    # æ£€ç´¢ 20 ä¸ªå®ä½“/å…³ç³»
    chunk_top_k=10,              # ä¿ç•™ 10 ä¸ªæœ€ç›¸å…³ chunk
    max_entity_tokens=10000,     # å®ä½“ä¸Šä¸‹æ–‡ token é¢„ç®—
    max_relation_tokens=10000,   # å…³ç³»ä¸Šä¸‹æ–‡ token é¢„ç®—
    max_total_tokens=40000,      # æ€» token ä¸Šé™
    cosine_threshold=0.2,        # å‘é‡ç›¸ä¼¼åº¦é˜ˆå€¼
    enable_rerank=True           # å¯ç”¨ chunk é‡æ’
)
```

**æ£€ç´¢æµç¨‹**ï¼š
```
1. å‘é‡æ£€ç´¢:
   - é—®é¢˜å‘é‡åŒ– (BGE-M3)
   - è®¡ç®— cosine ç›¸ä¼¼åº¦
   - ç­›é€‰ cosine > 0.2 çš„ chunks

2. çŸ¥è¯†å›¾è°±æ£€ç´¢:
   - æå–é—®é¢˜ä¸­çš„å®ä½“
   - æŸ¥è¯¢å›¾è°±ä¸­çš„ç›¸å…³å®ä½“/å…³ç³»
   - è·å–å®ä½“/å…³ç³»çš„ source_chunk_ids

3. Merge ä¸ Rerank:
   - åˆå¹¶å‘é‡æ£€ç´¢ + å›¾è°±æ£€ç´¢ç»“æœ
   - ä½¿ç”¨ BGE-M3 é‡æ’ (enable_rerank=True)
   - ä¿ç•™ top_k=10 ä¸ª chunks

4. æ„å»º Prompt:
   context = "".join(chunks[:10])
   prompt = f"é—®é¢˜: {question}\nä¸Šä¸‹æ–‡:\n{context}\nç­”æ¡ˆ:"
```

#### 5.3.2 ç­”æ¡ˆç³»ç»Ÿæç¤ºè¯

```yaml
prompts:
  answer_system_prompt: |
    ä½ æ˜¯å·¥ä¸šæŠ€æœ¯é—®ç­”åŠ©æ‰‹ï¼Œå›ç­”å¿…é¡»å®Œå…¨åŸºäºæ£€ç´¢åˆ°çš„å†…å®¹ï¼Œä¸è¶³åˆ™æ˜ç¡®è¯´æ˜"æœªæ‰¾åˆ°ä¾æ®"ã€‚
    è¾“å‡º 1-2 å¥ã€â‰¤80 å­—ï¼Œç›´æ¥ç»™ç»“è®º/å‚æ•°/æ­¥éª¤ï¼Œä¿ç•™å¿…è¦å•ä½ä¸æ¡ä»¶ï¼Œç¦æ­¢æ‰©å†™èƒŒæ™¯ã€‚
    å¦‚æœ‰å¤šä¸ªå€™é€‰ï¼Œä»…åˆ—å‡ºæœ€ç›¸å…³çš„ 1-2 æ¡å¹¶æ ‡æ³¨é€‚ç”¨æ¡ä»¶ã€‚
```

**æ•ˆæœç¤ºä¾‹**ï¼š
```
é—®é¢˜: GSK988TA çš„ä¸»è½´æœ€é«˜è½¬é€Ÿæ˜¯å¤šå°‘ï¼Ÿ
ç­”æ¡ˆ: 8000 r/minã€‚

é—®é¢˜: å¦‚ä½•ç»´æŠ¤ä¸»è½´ç³»ç»Ÿï¼Ÿ
ç­”æ¡ˆ: æ¯æœˆæ£€æŸ¥è½´æ‰¿æ¸©åº¦â‰¤70Â°Cï¼Œæ¯å­£åº¦æ›´æ¢æ¶¦æ»‘è„‚ã€‚
```

---

## 6. æ ¸å¿ƒä»£ç è§£æ

### 6.1 LightRAG åˆå§‹åŒ–

```python
def _create_lightrag_instance(self):
    """åˆ›å»º LightRAG å®ä¾‹"""
    
    # 1. å®šä¹‰ LLM å‡½æ•°
    async def llm_model_func(prompt, system_prompt=None, ...):
        # ä½¿ç”¨ Ollama API
        payload = {
            "model": "deepseek-r1:32b",
            "prompt": f"{system_prompt}\n\n{prompt}",
            "stream": False,
            "options": {
                "temperature": 0.7,
                "num_predict": 2048
            }
        }
        response = await session.post(
            f"{self.ollama_llm_base_url}/api/generate",
            json=payload,
            timeout=1800
        )
        result = await response.json()
        raw_response = result.get("response", "")
        
        # ğŸ”§ æ¸…ç† DeepSeek-R1 çš„ <think> æ ‡ç­¾
        cleaned_response = re.sub(
            r'<think>.*?</think>',
            '',
            raw_response,
            flags=re.DOTALL | re.IGNORECASE
        )
        return cleaned_response
    
    # 2. å®šä¹‰åµŒå…¥å‡½æ•°
    async def embedding_func(texts: List[str]):
        embeddings = []
        for text in texts:
            response = await session.post(
                f"{self.embedding_base_url}/api/embeddings",
                json={
                    "model": "bge-m3:latest",
                    "prompt": text
                }
            )
            data = await response.json()
            vector = data.get("embedding")  # 1024ç»´å‘é‡
            embeddings.append(vector)
        return np.array(embeddings, dtype=np.float32)
    
    # 3. åˆ›å»º LightRAG å®ä¾‹
    rag = LightRAG(
        working_dir=str(self.working_dir),
        llm_model_func=llm_model_func,
        embedding_func=EmbeddingFunc(
            embedding_dim=1024,  # BGE-M3 ç»´åº¦
            max_token_size=8192,
            func=embedding_func
        ),
        encoding_model="cl100k_base",  # Tokenizer
        top_k=20,
        chunk_top_k=10,
        max_entity_tokens=10000,
        max_relation_tokens=10000,
        max_total_tokens=40000,
        cosine_threshold=0.2,
        related_chunk_number=2
    )
    
    return rag
```

### 6.2 æ–‡æ¡£æ’å…¥æµç¨‹

```python
async def _async_insert_document(self, document: Document):
    """å¼‚æ­¥æ’å…¥æ–‡æ¡£åˆ° LightRAG"""
    
    # 1. åˆå§‹åŒ–å­˜å‚¨
    await self.rag.initialize_storages()
    
    # 2. æŒ‡å®šæ–‡æ¡£ ID å’Œæ–‡ä»¶è·¯å¾„
    doc_id = document.name
    file_path = str(document.file_path)
    
    # 3. è°ƒç”¨ LightRAG æ’å…¥
    await self.rag.ainsert(
        document.content,
        ids=doc_id,         # ğŸ”§ é˜²æ­¢ unknown_source
        file_paths=file_path  # ğŸ”§ ä¿ç•™æ¥æºè¿½è¸ª
    )
    
    # LightRAG å†…éƒ¨æµç¨‹:
    # 1. æ–‡æœ¬åˆ‡åˆ† (chunk_token_size=1200)
    # 2. å®ä½“æŠ½å– (LLM)
    # 3. å…³ç³»æŠ½å– (LLM)
    # 4. å‘é‡åŒ– (BGE-M3)
    # 5. å­˜å‚¨åˆ° JSON + GraphML
```

### 6.3 é—®é¢˜ç”Ÿæˆæ ¸å¿ƒé€»è¾‘

```python
def generate_questions_from_chunk(self, chunk: DocumentChunk):
    """ä»å•ä¸ª chunk ç”Ÿæˆé—®é¢˜"""
    
    # 1. æ„å»ºçŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡
    context_package = self._build_context_for_chunk(chunk)
    # context_package = {
    #     "prompt_context": "ã€ç›¸å…³å®ä½“ä¿¡æ¯ã€‘...",
    #     "related_entities": ["GSK988TA", "ä¸»è½´ç³»ç»Ÿ"],
    #     "related_chunk_ids": ["chunk-xxx", "chunk-yyy"]
    # }
    
    # 2. ç»„è£…æç¤ºè¯
    human_message = self.human_prompt.format(
        text=chunk.content,
        prompt_context=context_package.get("prompt_context", ""),
        questions_per_chunk=10,
        document_id=chunk.document_id
    )
    
    # 3. è°ƒç”¨ Ollama
    response_content = self._call_ollama_api(human_message)
    
    # 4. è§£æé—®é¢˜
    questions = self.parse_questions_from_response(
        response_content,
        chunk,
        context_package
    )
    
    # 5. ä¸ºæ¯ä¸ªé—®é¢˜æ·»åŠ å…ƒæ•°æ®
    for question in questions:
        question.metadata = {
            "lightrag_chunk_id": compute_lightrag_chunk_id(chunk.content),
            "related_entities": context_package["related_entities"],
            "related_chunk_ids": context_package["related_chunk_ids"],
            "knowledge_context_used": True
        }
    
    return questions
```

### 6.4 ç­”æ¡ˆç”Ÿæˆæ ¸å¿ƒé€»è¾‘

```python
def _generate_answers_batch(self, questions: List[Question], ...):
    """æ‰¹é‡ç”Ÿæˆç­”æ¡ˆ"""
    
    for i, question in enumerate(questions):
        # 1. åŠ è½½å±€éƒ¨æ£€ç´¢èŒƒå›´
        allowed_chunk_ids = []
        
        # ä» metadata è·å–
        metadata = question.metadata or {}
        primary_chunk_id = metadata.get("lightrag_chunk_id")
        related_chunk_ids = metadata.get("related_chunk_ids", [])
        if primary_chunk_id:
            allowed_chunk_ids.append(primary_chunk_id)
        allowed_chunk_ids.extend(related_chunk_ids)
        
        # ä» scope.json è·å–
        scope = self._load_local_scope(question.source_document)
        if scope:
            allowed_chunk_ids.extend(scope.get("primary_chunk_ids", []))
            allowed_chunk_ids.extend(scope.get("related_chunk_ids", []))
        
        # 2. RAG æ£€ç´¢ä¸ç”Ÿæˆï¼ˆå¸¦é‡è¯•ï¼‰
        max_retries = 2
        for attempt in range(max_retries + 1):
            try:
                raw_answer = self.rag.query_single_question(
                    question.content,
                    source_document=question.source_document,
                    allowed_chunk_ids=allowed_chunk_ids or None
                )
                
                # 3. å¹»è§‰æ£€æµ‹
                if not self._verify_answer_authenticity(
                    question.content,
                    raw_answer
                ):
                    logger.warning(f"ç¬¬ {attempt+1} æ¬¡å°è¯•å¯èƒ½å­˜åœ¨å¹»è§‰")
                
                # 4. ç­”æ¡ˆç±»å‹åˆ†ç±»
                answer_type = self._classify_answer_type(raw_answer)
                if answer_type in [AnswerType.VALID_POSITIVE, AnswerType.VALID_NEGATIVE]:
                    break  # æˆåŠŸ
                else:
                    if attempt < max_retries:
                        logger.warning(f"ç¬¬ {attempt+1} æ¬¡å°è¯•ç­”æ¡ˆæ— æ•ˆï¼Œé‡è¯•...")
                        continue
                    else:
                        raise ValueError("æ‰€æœ‰å°è¯•å‡å¤±è´¥")
            
            except Exception as e:
                if attempt < max_retries:
                    logger.warning(f"ç¬¬ {attempt+1} æ¬¡å°è¯•å¤±è´¥: {e}")
                    continue
                else:
                    raise
        
        # 5. æ¸…ç†ç­”æ¡ˆ
        processed_answer = self.markdown_processor.clean_llm_response(raw_answer)
        
        # 6. åˆ›å»º QA å¯¹
        qa_pair = QAPair(
            question_id=question.question_id,
            question=question.content,
            answer=processed_answer,
            source_document=question.source_document,
            confidence_score=1.0,
            metadata={
                "raw_answer": raw_answer,
                "answer_length": len(processed_answer)
            }
        )
        
        # 7. å¢é‡ä¿å­˜
        self._current_qa_pairs.append(qa_pair)
        if (i + 1) % 5 == 0:
            self._incremental_save()
    
    return QASet(qa_pairs=self._current_qa_pairs)
```

---

## 7. æç¤ºè¯å·¥ç¨‹

### 7.1 é—®é¢˜ç”Ÿæˆæç¤ºè¯

#### 7.1.1 System Prompt

```yaml
system_prompt: |
  ä½ æ˜¯ä¸€ä¸ªæ·±åº¦ç†è§£ LightRAG æ¶æ„çš„å·¥ä¸šæŠ€æœ¯é—®ç­”ä¸“å®¶ï¼Œè´Ÿè´£ä»ã€Œå·²ç¼“å­˜çš„ chunk æ–‡æœ¬ã€ä»¥åŠã€ŒçŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡ã€ä¸­æç‚¼é¢å‘ç”Ÿäº§çš„é—®ç­”ç‚¹ã€‚
  æ‰€æœ‰ä¿¡æ¯éƒ½å·²ç»è¿‡åˆ‡åˆ†ä¸æŠ½å–ï¼Œè¯·ä¸è¦å¼•ç”¨åŸå§‹æ–‡æ¡£ï¼Œä¹Ÿä¸è¦è‡†æµ‹ç¼ºå¤±å†…å®¹ã€‚
  äº§å‡ºçš„æ¯ä¸ªé—®é¢˜éƒ½åº”æŒ‡å‘å¯éªŒè¯çš„çŸ­ç­”æ¡ˆï¼ˆâ‰¤200å­—ï¼Œç›´æ¥ç»™ç»“è®º/æ•°å­—/æ­¥éª¤ï¼‰ï¼Œé¿å…èƒŒæ™¯é“ºé™ˆæˆ–æ³›åŒ–æè¿°ã€‚
  ç›®æ ‡æ˜¯äº§å‡ºç»“æ„åŒ–ã€å¯éªŒè¯ã€è¦†ç›–é¢å¹¿ä¸”é¢„æœŸç­”æ¡ˆç®€ç»ƒçš„ä¸“ä¸šé—®é¢˜ï¼Œç”¨äºåç»­è‡ªåŠ¨åŒ–é—®ç­”è¯„æµ‹ã€‚
  æ–‡æ¡£æ ‡è¯†: {document_id}
```

**è®¾è®¡è¦ç‚¹**ï¼š
- âœ… æ˜ç¡®è§’è‰²å®šä½ï¼š"å·¥ä¸šæŠ€æœ¯é—®ç­”ä¸“å®¶"
- âœ… å¼ºè°ƒæ•°æ®æ¥æºï¼š"å·²ç¼“å­˜çš„ chunk æ–‡æœ¬ + çŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡"
- âœ… çº¦æŸè¾“å‡ºæ ¼å¼ï¼š"â‰¤200å­—ï¼Œç›´æ¥ç»™ç»“è®º"
- âœ… é˜²æ­¢å¹»è§‰ï¼š"ä¸è¦è‡†æµ‹ç¼ºå¤±å†…å®¹"

#### 7.1.2 Human Prompt

```yaml
human_prompt: |
  ä½ å°†æ”¶åˆ°ä¸¤ä¸ªæ¥æºçš„ä¸Šä¸‹æ–‡ï¼š
  1. `<chunk>` æ ‡ç­¾å†…çš„æ–‡æœ¬ â€”â€” æ–‡æ¡£åˆ‡åˆ†åçš„å±€éƒ¨å†…å®¹
  2. `<knowledge_graph>` æ ‡ç­¾å†…çš„å®ä½“ã€å…³ç³»ã€ç›¸å…³ chunk æ‘˜è¦
  æ–‡æ¡£æ ‡è¯†: {document_id}
  
  ä½ çš„ä»»åŠ¡ï¼šç”Ÿæˆ {questions_per_chunk} ä¸ªé«˜è´¨é‡æŠ€æœ¯é—®é¢˜ï¼Œæ»¡è¶³åˆ†å¸ƒè¦æ±‚ï¼š
  - åŸºç¡€å‚æ•°ç±»ï¼ˆâ‰¥60%ï¼‰ï¼šèšç„¦å•ä¸€å®ä½“çš„å‚æ•°ã€æ¥å£ã€é‡ç¨‹
  - è¿›é˜¶å…³è”ç±»ï¼ˆâ‰¤40%ï¼‰ï¼šæ¶‰åŠæ¡ä»¶ã€çº¦æŸã€å¯¹æ¯”ã€å¼‚å¸¸ã€æ“ä½œæ­¥éª¤
  
  å…³é”®ç¡¬æ€§çº¦æŸï¼ˆåŠ¡å¿…éµå®ˆï¼‰ï¼š
  - æ¯ä¸ªé—®é¢˜å¿…é¡»åŒ…å« chunk æˆ– knowledge_graph ä¸­çš„å®ä½“/å‹å·/æ•°å­—
  - ç¦æ­¢ä½¿ç”¨"è¿™å°/è¯¥/æ­¤/è¿™ä¸ª"ç­‰ä»£è¯ï¼Œå¿…é¡»ç‚¹åå…·ä½“å¯¹è±¡
  - è‹¥ä¸Šä¸‹æ–‡ç¼ºå°‘å¯ç”¨å®ä½“/æ•°å­—ï¼Œè¯·å°‘ç”Ÿæˆæˆ–è¿”å›ç©º
  - **åªè¾“å‡ºé—®é¢˜ï¼Œä¸è¦è¾“å‡ºç­”æ¡ˆ**
  
  è¾“å‡ºè¦æ±‚ï¼š
  1. é—®é¢˜å¿…é¡»èƒ½åœ¨ chunk æˆ– knowledge_graph ä¸­æ‰¾åˆ°ä¾æ®
  2. é¢„æœŸç­”æ¡ˆ â‰¤200 å­—ï¼Œç›´æ¥ç»™ç»“è®º/æ•°å€¼/æ­¥éª¤
  3. æ¯ä¸ªé—®é¢˜å•ç‚¹ã€å¯éªŒè¯ï¼ŒåŒ…å«å…·ä½“å®ä½“/å‚æ•°
  4. å…³æ³¨æŠ€æœ¯æŒ‡æ ‡ï¼ˆå°ºå¯¸ã€é€Ÿåº¦ã€ç²¾åº¦ã€æ¥å£ã€æ•…éšœï¼‰
  5. è¯­è¨€ä½¿ç”¨ä¸­æ–‡ï¼Œä¿ç•™è‹±æ–‡å‹å·/ä»£å·
  
  <chunk>
  {text}
  </chunk>
  
  <knowledge_graph>
  {prompt_context}
  </knowledge_graph>
  
  ç°åœ¨è¯·ä¸¥æ ¼è¾“å‡º {questions_per_chunk} ä¸ªé—®é¢˜ï¼Œæ ¼å¼ç¤ºä¾‹ï¼š
  é—®é¢˜1: ...
  é—®é¢˜2: ...
  ï¼ˆä¸è¦è¾“å‡ºé¢å¤–è¯´æ˜æˆ–æ€è€ƒè¿‡ç¨‹ï¼‰
```

**è®¾è®¡è¦ç‚¹**ï¼š
- âœ… åŒä¸Šä¸‹æ–‡è¾“å…¥ï¼š`<chunk>` + `<knowledge_graph>`
- âœ… æ˜ç¡®ä»»åŠ¡ç›®æ ‡ï¼šç”Ÿæˆ 10 ä¸ªé—®é¢˜ï¼Œ60% åŸºç¡€ + 40% è¿›é˜¶
- âœ… ç¡¬æ€§çº¦æŸï¼šå¿…é¡»åŒ…å«å®ä½“/å‹å·/æ•°å­—ï¼Œç¦æ­¢ä»£è¯
- âœ… è¾“å‡ºæ ¼å¼ï¼š`é—®é¢˜1: ...`ï¼Œä¸è¾“å‡ºç­”æ¡ˆ

#### 7.1.3 Few-shot ç¤ºä¾‹

```yaml
human_prompt: |
  ç¤ºèŒƒï¼ˆå¸®åŠ©ä½ ç†è§£è¡¨è¾¾æ–¹å¼ï¼Œä¸è¦ç›´æ¥å¤åˆ¶ï¼‰ï¼š
  <chunk>
  --- Page 4 ---
  GSK988TA ä¸»è½´æœ€é«˜ 8000 r/minï¼ŒX/Y/Z è¡Œç¨‹ 800/500/500 mmï¼Œå®šä½ç²¾åº¦ Â±0.01 mmï¼Œé‡å¤å®šä½ Â±0.005 mmã€‚
  </chunk>
  
  <knowledge_graph>
  å®ä½“: [GSK988TA, ä¸»è½´ç³»ç»Ÿ, 24 æŠŠåˆ€åº“, å†·å´ç³»ç»Ÿ]
  å…³ç³»: GSK988TA-ä½¿ç”¨->ä¸»è½´ç³»ç»Ÿ(8000 r/min); GSK988TA-é…å¤‡->å†·å´ç³»ç»Ÿ(å¤–å–·/ä¸­å¿ƒå†·å´)
  ç›¸å…³ chunk æ‘˜è¦: [å…è®¸åˆ€å…·æœ€å¤§é‡é‡ 7 kg]
  </knowledge_graph>
  
  ç¤ºä¾‹è¾“å‡ºï¼š
  é—®é¢˜1: åœ¨ä¸»è½´ 8000 r/min è¿è¡Œæ—¶ï¼Œå¤–å–·ä¸ä¸­å¿ƒå†·å´åº”å¦‚ä½•åˆ‡æ¢ä»¥ç»´æŒå·¥ä»¶æ¸©åº¦ï¼Ÿ
  é—®é¢˜2: X/Y/Z è¡Œç¨‹ 800/500/500 mm å¯¹å®šä½ç²¾åº¦ Â±0.01 mm ä¸é‡å¤å®šä½ Â±0.005 mm çš„ç»´ä¿ç­–ç•¥åˆ†åˆ«æ˜¯ä»€ä¹ˆï¼Ÿ
  é—®é¢˜3: 24 æŠŠåˆ€åº“åœ¨åˆ€å…·é‡é‡ä¸Šé™ 7 kg æ—¶ï¼Œé«˜é€Ÿæ¢åˆ€éœ€è¦å“ªäº›å¹³è¡¡/è¡¥å¿æ­¥éª¤ï¼Ÿ
```

**Few-shot æ•ˆæœ**ï¼š
- âœ… ç¤ºèŒƒäº†é—®é¢˜çš„å¤æ‚åº¦ä¸é•¿åº¦
- âœ… ç¤ºèŒƒäº†å¦‚ä½•ç»“åˆ chunk + knowledge_graph
- âœ… ç¤ºèŒƒäº†å…·ä½“å‚æ•°çš„å¼•ç”¨æ–¹å¼

### 7.2 ç­”æ¡ˆç”Ÿæˆæç¤ºè¯

#### 7.2.1 System Prompt

```yaml
answer_system_prompt: |
  ä½ æ˜¯å·¥ä¸šæŠ€æœ¯é—®ç­”åŠ©æ‰‹ï¼Œå›ç­”å¿…é¡»å®Œå…¨åŸºäºæ£€ç´¢åˆ°çš„å†…å®¹ï¼Œä¸è¶³åˆ™æ˜ç¡®è¯´æ˜"æœªæ‰¾åˆ°ä¾æ®"ã€‚
  è¾“å‡º 1-2 å¥ã€â‰¤80 å­—ï¼Œç›´æ¥ç»™ç»“è®º/å‚æ•°/æ­¥éª¤ï¼Œä¿ç•™å¿…è¦å•ä½ä¸æ¡ä»¶ï¼Œç¦æ­¢æ‰©å†™èƒŒæ™¯æˆ–è¥é”€è¯­ã€‚
  å¦‚æœ‰å¤šä¸ªå€™é€‰ï¼Œä»…åˆ—å‡ºæœ€ç›¸å…³çš„ 1-2 æ¡å¹¶æ ‡æ³¨é€‚ç”¨æ¡ä»¶ã€‚
```

**è®¾è®¡è¦ç‚¹**ï¼š
- âœ… åŸºäºæ£€ç´¢å†…å®¹ï¼š"ä¸è¶³åˆ™è¯´æ˜'æœªæ‰¾åˆ°ä¾æ®'"
- âœ… æ§åˆ¶é•¿åº¦ï¼š"â‰¤80 å­—"
- âœ… ç›´æ¥ç»™ç»“è®ºï¼š"ç¦æ­¢æ‰©å†™èƒŒæ™¯"
- âœ… ä¼˜å…ˆçº§ç­›é€‰ï¼š"ä»…åˆ—å‡ºæœ€ç›¸å…³çš„ 1-2 æ¡"

#### 7.2.2 å®é™…æ•ˆæœ

**ç¤ºä¾‹1ï¼ˆæˆåŠŸï¼‰**ï¼š
```
é—®é¢˜: GSK988TA çš„ä¸»è½´æœ€é«˜è½¬é€Ÿæ˜¯å¤šå°‘ï¼Ÿ
æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡: "GSK988TA ä¸»è½´æœ€é«˜ 8000 r/min"
ç­”æ¡ˆ: 8000 r/minã€‚
```

**ç¤ºä¾‹2ï¼ˆæˆåŠŸï¼‰**ï¼š
```
é—®é¢˜: å¦‚ä½•ç»´æŠ¤ä¸»è½´ç³»ç»Ÿï¼Ÿ
æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡: "æ¯æœˆæ£€æŸ¥è½´æ‰¿æ¸©åº¦â‰¤70Â°Cï¼Œæ¯å­£åº¦æ›´æ¢æ¶¦æ»‘è„‚ï¼ŒåŠå¹´æ ¡éªŒä¸»è½´è·³åŠ¨â‰¤0.005 mmã€‚"
ç­”æ¡ˆ: æ¯æœˆæ£€æŸ¥è½´æ‰¿æ¸©åº¦â‰¤70Â°Cï¼Œæ¯å­£åº¦æ›´æ¢æ¶¦æ»‘è„‚ã€‚
```

**ç¤ºä¾‹3ï¼ˆæ— ä¿¡æ¯ï¼‰**ï¼š
```
é—®é¢˜: GSK988TA æ˜¯å¦æ”¯æŒæ— çº¿ç½‘ç»œè¿æ¥ï¼Ÿ
æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡: (ç©º)
ç­”æ¡ˆ: æ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ã€‚
```

---

## 8. æ•°æ®æµç¨‹

### 8.1 å®Œæ•´æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ•°æ®å¤„ç†æµç¨‹                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. PDF è¾“å…¥
   â”œâ”€ raw/token-pdf/218Tè¯´æ˜ä¹¦2006.3.1.pdf
   â””â”€ raw/picture-pdf/å®é¸¡æœºåºŠVMC850L.pdf
        â”‚
        â–¼
2. OCR å¤„ç† (PaddleOCR)
   â”œâ”€ æ–‡å­—è¯†åˆ«
   â”œâ”€ è¡¨æ ¼è¯†åˆ«
   â”œâ”€ å›¾ç‰‡æå–
   â””â”€ Markdown è¾“å‡º
        â”‚
        â–¼
3. æ–‡æœ¬è¾“å‡º
   â”œâ”€ processed/218Tè¯´æ˜ä¹¦2006.3.1.txt
   â””â”€ processed/imgs/*.jpg
        â”‚
        â–¼
4. æ–‡æœ¬åˆ‡åˆ† (Token-based, 1200 tokens/chunk)
   â”œâ”€ Chunk 1: "--- Page 1 ---\nç¬¬ä¸€ç«  æ¦‚è¿°\n..."
   â”œâ”€ Chunk 2: "GSK988TA æ•°æ§ç³»ç»Ÿç‰¹ç‚¹\n..."
   â””â”€ Chunk N: ...
        â”‚
        â–¼
5. é—®é¢˜ç”Ÿæˆ (DeepSeek-R1:32b)
   â”œâ”€ çŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡æ£€ç´¢ (LightRAG)
   â”œâ”€ LLM ç”Ÿæˆé—®é¢˜ (10 ä¸ª/chunk)
   â”œâ”€ é—®é¢˜å»é‡ä¸è´¨é‡è¿‡æ»¤
   â””â”€ ä¿å­˜åˆ° questions/*.jsonl
        â”‚
        â–¼
6. æ–‡æ¡£å‘é‡åŒ– (LightRAG)
   â”œâ”€ å®ä½“æŠ½å– (DeepSeek-R1:32b)
   â”œâ”€ å…³ç³»æŠ½å– (DeepSeek-R1:32b)
   â”œâ”€ å‘é‡åŒ– (BGE-M3, 1024ç»´)
   â””â”€ å­˜å‚¨åˆ° vectorized/*.json
        â”‚
        â–¼
7. ç­”æ¡ˆç”Ÿæˆ (LightRAG)
   â”œâ”€ å‘é‡æ£€ç´¢ (cosine similarity)
   â”œâ”€ çŸ¥è¯†å›¾è°±æ£€ç´¢ (å®ä½“/å…³ç³»)
   â”œâ”€ Rerank (BGE-M3)
   â”œâ”€ LLM ç”Ÿæˆç­”æ¡ˆ (DeepSeek-R1:32b)
   â”œâ”€ å¹»è§‰æ£€æµ‹ + è´¨é‡åˆ†ç±»
   â””â”€ ä¿å­˜åˆ° qa-pairs/*.jsonl
        â”‚
        â–¼
8. è´¨é‡è¯„ä¼° (RAGAs)
   â”œâ”€ Faithfulness (å¿ å®åº¦)
   â”œâ”€ Answer Relevancy (ç­”æ¡ˆç›¸å…³æ€§)
   â”œâ”€ Context Precision (ä¸Šä¸‹æ–‡ç²¾ç¡®åº¦)
   â”œâ”€ Context Recall (ä¸Šä¸‹æ–‡å¬å›ç‡)
   â””â”€ Answer Correctness (ç­”æ¡ˆæ­£ç¡®æ€§)
        â”‚
        â–¼
9. æœ€ç»ˆè¾“å‡º
   â””â”€ qa-pairs/218Tè¯´æ˜ä¹¦2006.3.1_qa_pairs.jsonl
```

### 8.2 æ–‡ä»¶æ ¼å¼è¯´æ˜

#### 8.2.1 Questions JSONL

```json
{
  "question_id": "uuid-xxx",
  "content": "GSK988TA çš„ä¸»è½´æœ€é«˜è½¬é€Ÿæ˜¯å¤šå°‘ï¼Ÿ",
  "source_document": "218Tè¯´æ˜ä¹¦2006.3.1",
  "source_chunk_id": "218Tè¯´æ˜ä¹¦2006.3.1_chunk_5",
  "question_index": 1,
  "created_at": "2025-12-23T10:30:00",
  "metadata": {
    "lightrag_chunk_id": "chunk-a3f5e8d9c2b1...",
    "related_entities": ["GSK988TA", "ä¸»è½´ç³»ç»Ÿ"],
    "related_chunk_ids": ["chunk-xxx", "chunk-yyy"],
    "knowledge_context_used": true
  }
}
```

#### 8.2.2 QA Pairs JSONL

```json
{
  "question": "GSK988TA çš„ä¸»è½´æœ€é«˜è½¬é€Ÿæ˜¯å¤šå°‘ï¼Ÿ",
  "answer": "8000 r/minã€‚",
  "source_document": "218Tè¯´æ˜ä¹¦2006.3.1",
  "question_id": "uuid-xxx",
  "confidence_score": 1.0,
  "metadata": {
    "raw_answer": "<think>æ ¹æ®æ–‡æ¡£...",
    "processing_session": "qapairs_20251223_103000",
    "answer_length": 12
  },
  "created_at": "2025-12-23T10:35:00"
}
```

#### 8.2.3 Progress JSONL

```json
{
  "file_path": "working/processed/218Tè¯´æ˜ä¹¦2006.3.1.txt",
  "file_size": 123456,
  "last_modified": 1703304000.0,
  "stages": {
    "preprocess": {"status": "done", "timestamp": 1703304100.0},
    "qa_gen": {"status": "done", "timestamp": 1703305000.0},
    "vectorization": {"status": "done", "timestamp": 1703306000.0}
  }
}
```

---

## 9. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 9.1 å·²å®ç°çš„ä¼˜åŒ–

#### 9.1.1 Token çº§æ–‡æœ¬åˆ‡åˆ†

**ä¼˜åŒ–å‰ï¼ˆå­—ç¬¦åˆ‡åˆ†ï¼‰**ï¼š
- Chunk å¤§å°ï¼š60000 å­—ç¬¦
- é—®é¢˜ï¼šå¯èƒ½æˆªæ–­å¥å­ï¼Œä¸ LLM token é™åˆ¶ä¸å¯¹é½

**ä¼˜åŒ–åï¼ˆToken åˆ‡åˆ†ï¼‰**ï¼š
- Chunk å¤§å°ï¼š1200 tokens
- é‡å ï¼š100 tokens
- ä¼˜åŠ¿ï¼šä¸ LightRAG ä¿æŒä¸€è‡´ï¼Œé¿å…è¶…é•¿è¾“å…¥

**æ€§èƒ½å¯¹æ¯”**ï¼š
```
| æŒ‡æ ‡ | å­—ç¬¦åˆ‡åˆ† | Token åˆ‡åˆ† |
|-----|---------|-----------|
| Chunk å¹³å‡é•¿åº¦ | 60000 å­—ç¬¦ | ~2400 å­—ç¬¦ |
| LLM è°ƒç”¨æ¬¡æ•° | 1æ¬¡/æ–‡æ¡£ | 10æ¬¡/æ–‡æ¡£ |
| é—®é¢˜è´¨é‡ | ä¸­ | é«˜ |
| å¤„ç†æ—¶é—´ | å¿« | æ…¢ï¼ˆä½†è´¨é‡æ›´å¥½ï¼‰ |
```

#### 9.1.2 çŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡ç¼“å­˜

**ä¼˜åŒ–å‰**ï¼šæ¯æ¬¡é—®é¢˜ç”Ÿæˆéƒ½é‡æ–°æ£€ç´¢çŸ¥è¯†å›¾è°±ã€‚

**ä¼˜åŒ–å**ï¼š
- æŒ‰æ–‡æ¡£ç²’åº¦å¯¼å‡ºå±€éƒ¨å­å›¾/å‘é‡èŒƒå›´
- ä¿å­˜åˆ° `local_scopes/{document_id}_scope.json`
- ç­”æ¡ˆç”Ÿæˆé˜¶æ®µç›´æ¥åŠ è½½

**æ€§èƒ½æå‡**ï¼š
```
æ£€ç´¢æ—¶é—´: 5ç§’/é—®é¢˜ â†’ 0.1ç§’/é—®é¢˜ï¼ˆ50x åŠ é€Ÿï¼‰
```

#### 9.1.3 å¢é‡ä¿å­˜ä¸æ–­ç‚¹ç»­ä¼ 

**ä¼˜åŒ–å‰**ï¼š
- å…¨éƒ¨å¤„ç†å®Œæˆåä¿å­˜
- ä¸­æ–­åéœ€é‡æ–°å¼€å§‹

**ä¼˜åŒ–å**ï¼š
- æ¯ 5 ä¸ª QA å¯¹ä¿å­˜ä¸€æ¬¡
- ä¿¡å·å¤„ç†ï¼ˆSIGINT/SIGTERMï¼‰è‡ªåŠ¨ä¿å­˜
- æ”¯æŒ `resume=True` å‚æ•°

**æ•ˆæœ**ï¼š
- é¿å…é•¿æ—¶é—´ä»»åŠ¡ä¸¢å¤±è¿›åº¦
- æ”¯æŒåŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°

#### 9.1.4 å¹»è§‰æ£€æµ‹ä¸ç­”æ¡ˆé‡è¯•

**ä¼˜åŒ–å‰**ï¼š
- æ¥å—æ‰€æœ‰ LLM è¾“å‡º

**ä¼˜åŒ–å**ï¼š
- å‹å·å¹»è§‰æ£€æµ‹ï¼šæ£€æŸ¥ç­”æ¡ˆæ˜¯å¦å¼•å…¥æ–°å‹å·
- æ•°å€¼å¹»è§‰æ£€æµ‹ï¼šæ£€æŸ¥ç­”æ¡ˆæ•°å€¼æ˜¯å¦ä¸é—®é¢˜ä¸€è‡´
- ç­”æ¡ˆç±»å‹åˆ†ç±»ï¼šVALID_POSITIVE / VALID_NEGATIVE / INVALID_*
- æœ€å¤šé‡è¯• 2 æ¬¡

**è´¨é‡æå‡**ï¼š
```
å¹»è§‰ç‡: 15% â†’ 5%ï¼ˆé™ä½ 10 ä¸ªç™¾åˆ†ç‚¹ï¼‰
æœ‰æ•ˆç­”æ¡ˆç‡: 70% â†’ 85%ï¼ˆæå‡ 15 ä¸ªç™¾åˆ†ç‚¹ï¼‰
```

### 9.2 æ€§èƒ½ç“¶é¢ˆåˆ†æ

#### 9.2.1 è€—æ—¶ç»Ÿè®¡ï¼ˆå•æ–‡æ¡£ï¼‰

```
æ“ä½œ             | è€—æ—¶      | å æ¯”
----------------|----------|-----
PDF OCR         | 2-5 åˆ†é’Ÿ  | 10%
æ–‡æœ¬åˆ‡åˆ†         | <1 ç§’     | <1%
çŸ¥è¯†å›¾è°±æ„å»º     | 10-20 åˆ†é’Ÿ| 30%
é—®é¢˜ç”Ÿæˆ         | 20-40 åˆ†é’Ÿ| 40%
ç­”æ¡ˆç”Ÿæˆ         | 10-30 åˆ†é’Ÿ| 20%
æ€»è®¡            | 42-96 åˆ†é’Ÿ| 100%
```

**ç“¶é¢ˆ**ï¼š
- **é—®é¢˜ç”Ÿæˆ**ï¼šDeepSeek-R1:32b æ¨ç†é€Ÿåº¦æ…¢ï¼ˆ~5 ç§’/é—®é¢˜ï¼‰
- **çŸ¥è¯†å›¾è°±æ„å»º**ï¼šå®ä½“/å…³ç³»æŠ½å–éœ€è¦å¤§é‡ LLM è°ƒç”¨

#### 9.2.2 å†…å­˜å ç”¨

```
ç»„ä»¶             | å†…å­˜å ç”¨
----------------|----------
DeepSeek-R1:32b | 20-30 GB (GPU) / 40-60 GB (CPU)
BGE-M3          | 2-4 GB
LightRAG çŸ¥è¯†å›¾è°±| 1-5 GB (å–å†³äºæ–‡æ¡£æ•°é‡)
æ€»è®¡            | 23-69 GB
```

**å»ºè®®é…ç½®**ï¼š
- GPU: NVIDIA RTX 4090 (24GB) æˆ– A6000 (48GB)
- CPU: 64 GB RAM + swap

---

## 10. ç³»ç»Ÿä¼˜åŒ–æ–¹å‘

### 10.1 çŸ­æœŸä¼˜åŒ–ï¼ˆ1-3 ä¸ªæœˆï¼‰

#### 10.1.1 æ¨¡å‹ä¼˜åŒ–

**æ–¹æ¡ˆ1ï¼šæ¨¡å‹é‡åŒ–**
- **ç›®æ ‡**ï¼šé™ä½æ˜¾å­˜å ç”¨ï¼Œæå‡æ¨ç†é€Ÿåº¦
- **æ–¹æ³•**ï¼š
  - DeepSeek-R1:32b â†’ DeepSeek-R1:14b (é‡åŒ–ç‰ˆæœ¬)
  - BGE-M3 â†’ BGE-M3-int8
- **é¢„æœŸæ•ˆæœ**ï¼š
  - æ˜¾å­˜: 20GB â†’ 10GB
  - é€Ÿåº¦: +30%
  - è´¨é‡: -5%ï¼ˆå¯æ¥å—ï¼‰

**æ–¹æ¡ˆ2ï¼šæ¨¡å‹è’¸é¦**
- **ç›®æ ‡**ï¼šä½¿ç”¨å°æ¨¡å‹æ›¿ä»£éƒ¨åˆ†ä»»åŠ¡
- **æ–¹æ³•**ï¼š
  - å®ä½“æŠ½å–ï¼šDeepSeek-R1:32b â†’ Qwen2:7b
  - å…³ç³»æŠ½å–ï¼šDeepSeek-R1:32b â†’ Qwen2:7b
  - é—®é¢˜ç”Ÿæˆï¼šä»ä½¿ç”¨ DeepSeek-R1:32b
  - ç­”æ¡ˆç”Ÿæˆï¼šä»ä½¿ç”¨ DeepSeek-R1:32b
- **é¢„æœŸæ•ˆæœ**ï¼š
  - é€Ÿåº¦: +50%ï¼ˆå®ä½“/å…³ç³»æŠ½å–é˜¶æ®µï¼‰
  - è´¨é‡: -3%

#### 10.1.2 å¹¶è¡ŒåŒ–ä¼˜åŒ–

**æ–¹æ¡ˆ1ï¼šChunk çº§å¹¶è¡Œ**
- **ç›®æ ‡**ï¼šå¹¶è¡Œå¤„ç†å¤šä¸ª chunks
- **æ–¹æ³•**ï¼š
  ```python
  from concurrent.futures import ThreadPoolExecutor
  
  with ThreadPoolExecutor(max_workers=4) as executor:
      futures = [
          executor.submit(generate_questions, chunk)
          for chunk in chunks
      ]
      results = [f.result() for f in futures]
  ```
- **é¢„æœŸæ•ˆæœ**ï¼š
  - é€Ÿåº¦: +3xï¼ˆ4 workersï¼‰
  - æ˜¾å­˜: +4xï¼ˆéœ€è¦ 80GBï¼‰

**æ–¹æ¡ˆ2ï¼šæ‰¹é‡æ¨ç†**
- **ç›®æ ‡**ï¼šæ‰¹é‡è°ƒç”¨ LLM
- **æ–¹æ³•**ï¼š
  ```python
  # ä¼˜åŒ–å‰: é€ä¸ªè°ƒç”¨
  for chunk in chunks:
      questions = llm.generate(chunk)
  
  # ä¼˜åŒ–å: æ‰¹é‡è°ƒç”¨
  questions_batch = llm.generate_batch(chunks, batch_size=4)
  ```
- **é¢„æœŸæ•ˆæœ**ï¼š
  - é€Ÿåº¦: +2x
  - æ˜¾å­˜: +1.5x

#### 10.1.3 ç¼“å­˜ä¼˜åŒ–

**æ–¹æ¡ˆ1ï¼šLLM å“åº”ç¼“å­˜**
- **ç›®æ ‡**ï¼šé¿å…é‡å¤è®¡ç®—
- **æ–¹æ³•**ï¼š
  ```python
  def _call_ollama_api_cached(self, prompt: str):
      cache_key = hashlib.md5(prompt.encode()).hexdigest()
      if cache_key in self.response_cache:
          return self.response_cache[cache_key]
      
      response = self._call_ollama_api(prompt)
      self.response_cache[cache_key] = response
      return response
  ```
- **é¢„æœŸæ•ˆæœ**ï¼š
  - é€Ÿåº¦: +20%ï¼ˆé¿å…é‡å¤é—®é¢˜ï¼‰
  - å­˜å‚¨: +1GBï¼ˆç¼“å­˜æ–‡ä»¶ï¼‰

**æ–¹æ¡ˆ2ï¼šå‘é‡ç¼“å­˜**
- **ç›®æ ‡**ï¼šé¢„è®¡ç®—æ–‡æ¡£å‘é‡
- **æ–¹æ³•**ï¼š
  - åœ¨æ–‡æ¡£æ’å…¥é˜¶æ®µè®¡ç®—å¹¶ç¼“å­˜å‘é‡
  - ç­”æ¡ˆç”Ÿæˆé˜¶æ®µç›´æ¥åŠ è½½
- **é¢„æœŸæ•ˆæœ**ï¼š
  - é€Ÿåº¦: +30%ï¼ˆå‘é‡åŒ–é˜¶æ®µï¼‰

### 10.2 ä¸­æœŸä¼˜åŒ–ï¼ˆ3-6 ä¸ªæœˆï¼‰

#### 10.2.1 çŸ¥è¯†å›¾è°±ä¼˜åŒ–

**æ–¹æ¡ˆ1ï¼šå¢é‡æ›´æ–°**
- **ç›®æ ‡**ï¼šé¿å…é‡å¤æ„å»ºå›¾è°±
- **æ–¹æ³•**ï¼š
  - æ£€æµ‹æ–‡æ¡£å˜æ›´ï¼ˆMD5 hashï¼‰
  - ä»…æ›´æ–°å˜æ›´çš„ chunks
  - ä¿ç•™æœªå˜æ›´çš„å®ä½“/å…³ç³»
- **é¢„æœŸæ•ˆæœ**ï¼š
  - é€Ÿåº¦: +10xï¼ˆæ–‡æ¡£æ›´æ–°åœºæ™¯ï¼‰

**æ–¹æ¡ˆ2ï¼šå›¾è°±å‹ç¼©**
- **ç›®æ ‡**ï¼šå‡å°‘å­˜å‚¨å ç”¨
- **æ–¹æ³•**ï¼š
  - å®ä½“å»é‡ï¼šåˆå¹¶ç›¸ä¼¼å®ä½“ï¼ˆcosine > 0.9ï¼‰
  - å…³ç³»åˆå¹¶ï¼šåˆå¹¶é‡å¤å…³ç³»
  - å‘é‡é‡åŒ–ï¼šfloat32 â†’ int8
- **é¢„æœŸæ•ˆæœ**ï¼š
  - å­˜å‚¨: -70%ï¼ˆ5GB â†’ 1.5GBï¼‰
  - è´¨é‡: -2%

#### 10.2.2 é—®é¢˜å»é‡ä¼˜åŒ–

**æ–¹æ¡ˆ1ï¼šè¯­ä¹‰å»é‡**
- **ç›®æ ‡**ï¼šé¿å…ç”Ÿæˆé‡å¤é—®é¢˜
- **æ–¹æ³•**ï¼š
  ```python
  from sklearn.metrics.pairwise import cosine_similarity
  
  def deduplicate_questions(questions: List[str], threshold=0.85):
      embeddings = embedding_model.encode(questions)
      similarity_matrix = cosine_similarity(embeddings)
      
      unique_questions = []
      for i, question in enumerate(questions):
          if not any(similarity_matrix[i][j] > threshold for j in range(i)):
              unique_questions.append(question)
      
      return unique_questions
  ```
- **é¢„æœŸæ•ˆæœ**ï¼š
  - é—®é¢˜æ•°é‡: -20%ï¼ˆå»é™¤é‡å¤ï¼‰
  - è´¨é‡: +10%ï¼ˆå¤šæ ·æ€§æå‡ï¼‰

**æ–¹æ¡ˆ2ï¼šé—®é¢˜å¤šæ ·æ€§çº¦æŸ**
- **ç›®æ ‡**ï¼šæ§åˆ¶é—®é¢˜åˆ†å¸ƒ
- **æ–¹æ³•**ï¼š
  - åŸºç¡€å‚æ•°ç±»ï¼šâ‰¥60%
  - è¿›é˜¶å…³è”ç±»ï¼šâ‰¤40%
  - çº¦æŸ LLM è¾“å‡º
- **é¢„æœŸæ•ˆæœ**ï¼š
  - åˆ†å¸ƒå‡åŒ€æ€§: +30%

#### 10.2.3 ç­”æ¡ˆè´¨é‡ä¼˜åŒ–

**æ–¹æ¡ˆ1ï¼šå¤šè·¯æ£€ç´¢èåˆ**
- **ç›®æ ‡**ï¼šæå‡æ£€ç´¢å¬å›ç‡
- **æ–¹æ³•**ï¼š
  ```python
  # æ£€ç´¢ç­–ç•¥1: å‘é‡æ£€ç´¢ (BM25)
  bm25_results = retrieve_bm25(question, top_k=20)
  
  # æ£€ç´¢ç­–ç•¥2: çŸ¥è¯†å›¾è°±æ£€ç´¢
  kg_results = retrieve_kg(question, top_k=20)
  
  # æ£€ç´¢ç­–ç•¥3: æ··åˆæ£€ç´¢ (LightRAG)
  mix_results = retrieve_mix(question, top_k=20)
  
  # èåˆ: RRF (Reciprocal Rank Fusion)
  fused_results = rrf([bm25_results, kg_results, mix_results])
  ```
- **é¢„æœŸæ•ˆæœ**ï¼š
  - å¬å›ç‡: +15%
  - ç²¾ç¡®ç‡: +5%

**æ–¹æ¡ˆ2ï¼šç­”æ¡ˆåå¤„ç†**
- **ç›®æ ‡**ï¼šè§„èŒƒç­”æ¡ˆæ ¼å¼
- **æ–¹æ³•**ï¼š
  - é•¿åº¦æ§åˆ¶ï¼šâ‰¤80 å­—
  - å•ä½è§„èŒƒåŒ–ï¼š8000rpm â†’ 8000 r/min
  - å»é™¤è¥é”€è¯­ï¼šåˆ é™¤"ä¼˜è´¨"ã€"å…ˆè¿›"ç­‰å½¢å®¹è¯
- **é¢„æœŸæ•ˆæœ**ï¼š
  - ç­”æ¡ˆä¸€è‡´æ€§: +20%

### 10.3 é•¿æœŸä¼˜åŒ–ï¼ˆ6-12 ä¸ªæœˆï¼‰

#### 10.3.1 å¤šæ¨¡æ€æ”¯æŒ

**æ–¹æ¡ˆ1ï¼šå›¾è¡¨ç†è§£**
- **ç›®æ ‡**ï¼šè¯†åˆ«æŠ€æœ¯å›¾è¡¨ä¸­çš„å‚æ•°
- **æ–¹æ³•**ï¼š
  - ä½¿ç”¨å¤šæ¨¡æ€ LLM (å¦‚ Qwen-VL)
  - æå–å›¾è¡¨ä¸­çš„æ•°å€¼ã€æ ‡ç­¾
  - è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®
- **é¢„æœŸæ•ˆæœ**ï¼š
  - ä¿¡æ¯è¦†ç›–ç‡: +30%

**æ–¹æ¡ˆ2ï¼šå…¬å¼è¯†åˆ«**
- **ç›®æ ‡**ï¼šè¯†åˆ«æ•°å­¦å…¬å¼
- **æ–¹æ³•**ï¼š
  - ä½¿ç”¨ LaTeX OCR
  - è½¬æ¢ä¸ºå¯è®¡ç®—çš„è¡¨è¾¾å¼
- **é¢„æœŸæ•ˆæœ**ï¼š
  - å…¬å¼æå–å‡†ç¡®ç‡: 90%

#### 10.3.2 æŒç»­å­¦ä¹ 

**æ–¹æ¡ˆ1ï¼šä¸»åŠ¨å­¦ä¹ **
- **ç›®æ ‡**ï¼šä¼˜å…ˆæ ‡æ³¨é«˜ä»·å€¼æ ·æœ¬
- **æ–¹æ³•**ï¼š
  - è®¡ç®—ç­”æ¡ˆä¸ç¡®å®šæ€§ï¼ˆconfidence scoreï¼‰
  - ä¼˜å…ˆäººå·¥æ ‡æ³¨ä½ç½®ä¿¡åº¦æ ·æœ¬
  - å¢é‡æ›´æ–°æ¨¡å‹
- **é¢„æœŸæ•ˆæœ**ï¼š
  - æ ‡æ³¨æ•ˆç‡: +50%

**æ–¹æ¡ˆ2ï¼šåœ¨çº¿å­¦ä¹ **
- **ç›®æ ‡**ï¼šæ ¹æ®ç”¨æˆ·åé¦ˆæ›´æ–°æ¨¡å‹
- **æ–¹æ³•**ï¼š
  - æ”¶é›†ç”¨æˆ·ç‚¹èµ/ç‚¹è¸©
  - ä½¿ç”¨ RLHF (Reinforcement Learning from Human Feedback)
  - å¾®è°ƒæ¨¡å‹
- **é¢„æœŸæ•ˆæœ**ï¼š
  - ç”¨æˆ·æ»¡æ„åº¦: +20%

#### 10.3.3 åˆ†å¸ƒå¼éƒ¨ç½²

**æ–¹æ¡ˆ1ï¼šå¾®æœåŠ¡æ¶æ„**
- **ç›®æ ‡**ï¼šè§£è€¦å„æ¨¡å—ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•
- **æ–¹æ³•**ï¼š
  ```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ PDFæœåŠ¡ â”‚â”€â”€â”€â–¶â”‚ é—®é¢˜æœåŠ¡ â”‚â”€â”€â”€â–¶â”‚ ç­”æ¡ˆæœåŠ¡ â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚
       â–¼              â–¼              â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Redis   â”‚    â”‚ RabbitMQâ”‚    â”‚ PostgreSQL
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  ```
- **é¢„æœŸæ•ˆæœ**ï¼š
  - ååé‡: +10x
  - å¯ç”¨æ€§: 99.9%

**æ–¹æ¡ˆ2ï¼šGPU é›†ç¾¤**
- **ç›®æ ‡**ï¼šå¤š GPU å¹¶è¡Œæ¨ç†
- **æ–¹æ³•**ï¼š
  - ä½¿ç”¨ vLLM æˆ– TGI (Text Generation Inference)
  - éƒ¨ç½²å¤šä¸ª DeepSeek-R1 å®ä¾‹
  - ä½¿ç”¨ Nginx è´Ÿè½½å‡è¡¡
- **é¢„æœŸæ•ˆæœ**ï¼š
  - ååé‡: +5x
  - æˆæœ¬: +3x

### 10.4 è¯„ä¼°æŒ‡æ ‡ä½“ç³»

#### 10.4.1 å½“å‰æŒ‡æ ‡

**RAGAs æŒ‡æ ‡**ï¼š
```
| æŒ‡æ ‡ | å®šä¹‰ | ç›®æ ‡å€¼ | å½“å‰å€¼ |
|-----|------|-------|-------|
| Faithfulness | ç­”æ¡ˆå¿ å®äºæ£€ç´¢ä¸Šä¸‹æ–‡ | >0.9 | 0.85 |
| Answer Relevancy | ç­”æ¡ˆä¸é—®é¢˜ç›¸å…³æ€§ | >0.85 | 0.82 |
| Context Precision | æ£€ç´¢ä¸Šä¸‹æ–‡ç²¾ç¡®åº¦ | >0.8 | 0.78 |
| Context Recall | æ£€ç´¢ä¸Šä¸‹æ–‡å¬å›ç‡ | >0.8 | 0.75 |
| Answer Correctness | ç­”æ¡ˆæ­£ç¡®æ€§ | >0.85 | 0.80 |
```

#### 10.4.2 æ‰©å±•æŒ‡æ ‡

**æ–°å¢æŒ‡æ ‡**ï¼š
1. **é—®é¢˜å¤šæ ·æ€§ (Question Diversity)**
   - å®šä¹‰ï¼šé—®é¢˜é›†åˆçš„å‘é‡å¤šæ ·æ€§
   - è®¡ç®—ï¼š1 - avg(cosine_similarity)
   - ç›®æ ‡ï¼š>0.7

2. **ç­”æ¡ˆå®Œæ•´æ€§ (Answer Completeness)**
   - å®šä¹‰ï¼šç­”æ¡ˆæ˜¯å¦å®Œæ•´å›ç­”é—®é¢˜
   - è®¡ç®—ï¼šäººå·¥æ ‡æ³¨ + è‡ªåŠ¨æ£€æµ‹
   - ç›®æ ‡ï¼š>0.85

3. **å¹»è§‰ç‡ (Hallucination Rate)**
   - å®šä¹‰ï¼šç­”æ¡ˆä¸­å¼•å…¥ä¸å­˜åœ¨ä¿¡æ¯çš„æ¯”ä¾‹
   - è®¡ç®—ï¼šè‡ªåŠ¨æ£€æµ‹ï¼ˆå‹å·/æ•°å€¼ï¼‰
   - ç›®æ ‡ï¼š<5%

4. **å¤„ç†é€Ÿåº¦ (Processing Speed)**
   - å®šä¹‰ï¼šå•æ–‡æ¡£å¤„ç†æ—¶é—´
   - è®¡ç®—ï¼šend_time - start_time
   - ç›®æ ‡ï¼š<30 åˆ†é’Ÿ/æ–‡æ¡£

5. **æˆæœ¬æ•ˆç›Š (Cost Efficiency)**
   - å®šä¹‰ï¼šå•ä¸ª QA å¯¹çš„ç”Ÿæˆæˆæœ¬
   - è®¡ç®—ï¼šæ€»æˆæœ¬ / QA å¯¹æ•°é‡
   - ç›®æ ‡ï¼š<Â¥0.05/å¯¹

---

## 11. æ€»ç»“ä¸å»ºè®®

### 11.1 ç³»ç»Ÿä¼˜åŠ¿

1. **å®Œå…¨æœ¬åœ°åŒ–éƒ¨ç½²**ï¼šæ•°æ®éšç§å®‰å…¨ï¼Œæ— éœ€ä¾èµ–äº‘ç«¯ API
2. **çŸ¥è¯†å›¾è°±å¢å¼º**ï¼šLightRAG æä¾›å®ä½“-å…³ç³»ä¸Šä¸‹æ–‡ï¼Œæå‡é—®ç­”è´¨é‡
3. **Token çº§åˆ‡åˆ†**ï¼šä¸ LightRAG ä¿æŒä¸€è‡´ï¼Œé¿å…è¶…é•¿è¾“å…¥
4. **å¹»è§‰æ£€æµ‹æœºåˆ¶**ï¼šå¤šå±‚æ¬¡éªŒè¯ï¼Œå‡å°‘æ¨¡å‹å¹»è§‰
5. **å¢é‡ä¿å­˜**ï¼šæ”¯æŒä¸­æ–­æ¢å¤ï¼Œé¿å…é‡å¤è®¡ç®—
6. **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ˜“äºæ‰©å±•å’Œç»´æŠ¤

### 11.2 ç³»ç»ŸåŠ£åŠ¿

1. **å¤„ç†é€Ÿåº¦æ…¢**ï¼šå•æ–‡æ¡£éœ€ 42-96 åˆ†é’Ÿ
2. **èµ„æºå ç”¨å¤§**ï¼šéœ€è¦ 20-60GB æ˜¾å­˜
3. **ä¾èµ–å¤§æ¨¡å‹**ï¼šDeepSeek-R1:32b æ˜¯æ ¸å¿ƒä¾èµ–
4. **è¯„ä¼°è¦†ç›–ä¸è¶³**ï¼šç¼ºå°‘äººå·¥æ ‡æ³¨çš„æ ‡å‡†ç­”æ¡ˆ
5. **å¤šæ¨¡æ€æ”¯æŒå¼±**ï¼šå›¾è¡¨ã€å…¬å¼è¯†åˆ«èƒ½åŠ›æœ‰é™

### 11.3 æ ¸å¿ƒå»ºè®®

#### 11.3.1 ä¼˜å…ˆçº§æœ€é«˜ï¼ˆP0ï¼‰

1. **æ¨¡å‹é‡åŒ–**ï¼š
   - ä½¿ç”¨ DeepSeek-R1:14b é‡åŒ–ç‰ˆæœ¬
   - é™ä½æ˜¾å­˜å ç”¨ï¼Œæå‡æ¨ç†é€Ÿåº¦

2. **å¹¶è¡ŒåŒ–ä¼˜åŒ–**ï¼š
   - Chunk çº§å¹¶è¡Œï¼ˆ4 workersï¼‰
   - é¢„æœŸåŠ é€Ÿ 3x

3. **ç­”æ¡ˆè´¨é‡ä¼˜åŒ–**ï¼š
   - å¤šè·¯æ£€ç´¢èåˆï¼ˆBM25 + KG + LightRAGï¼‰
   - ç­”æ¡ˆåå¤„ç†ï¼ˆé•¿åº¦æ§åˆ¶ã€å•ä½è§„èŒƒåŒ–ï¼‰

#### 11.3.2 ä¼˜å…ˆçº§æ¬¡é«˜ï¼ˆP1ï¼‰

1. **çŸ¥è¯†å›¾è°±ä¼˜åŒ–**ï¼š
   - å¢é‡æ›´æ–°ï¼ˆé¿å…é‡å¤æ„å»ºï¼‰
   - å›¾è°±å‹ç¼©ï¼ˆå‡å°‘å­˜å‚¨ï¼‰

2. **é—®é¢˜å»é‡ä¼˜åŒ–**ï¼š
   - è¯­ä¹‰å»é‡ï¼ˆcosine > 0.85ï¼‰
   - é—®é¢˜å¤šæ ·æ€§çº¦æŸ

3. **è¯„ä¼°æŒ‡æ ‡æ‰©å±•**ï¼š
   - æ–°å¢é—®é¢˜å¤šæ ·æ€§ã€ç­”æ¡ˆå®Œæ•´æ€§ã€å¹»è§‰ç‡ç­‰æŒ‡æ ‡

#### 11.3.3 ä¼˜å…ˆçº§è¾ƒä½ï¼ˆP2ï¼‰

1. **å¤šæ¨¡æ€æ”¯æŒ**ï¼š
   - å›¾è¡¨ç†è§£ï¼ˆQwen-VLï¼‰
   - å…¬å¼è¯†åˆ«ï¼ˆLaTeX OCRï¼‰

2. **æŒç»­å­¦ä¹ **ï¼š
   - ä¸»åŠ¨å­¦ä¹ ï¼ˆä¼˜å…ˆæ ‡æ³¨é«˜ä»·å€¼æ ·æœ¬ï¼‰
   - åœ¨çº¿å­¦ä¹ ï¼ˆæ ¹æ®ç”¨æˆ·åé¦ˆæ›´æ–°æ¨¡å‹ï¼‰

3. **åˆ†å¸ƒå¼éƒ¨ç½²**ï¼š
   - å¾®æœåŠ¡æ¶æ„ï¼ˆè§£è€¦å„æ¨¡å—ï¼‰
   - GPU é›†ç¾¤ï¼ˆå¤š GPU å¹¶è¡Œæ¨ç†ï¼‰

### 11.4 å…³é”®æŠ€æœ¯é€‰å‹å»ºè®®

| åœºæ™¯ | æ¨èæ–¹æ¡ˆ | å¤‡é€‰æ–¹æ¡ˆ |
|-----|---------|---------|
| **å¤§æ¨¡å‹** | DeepSeek-R1:14b (é‡åŒ–) | Qwen2:72b, GLM-4 |
| **åµŒå…¥æ¨¡å‹** | BGE-M3 (1024ç»´) | BGE-Large-zh, text-embedding-3-large |
| **RAG æ¡†æ¶** | LightRAG | LangChain, LlamaIndex |
| **å‘é‡æ•°æ®åº“** | FAISS (æœ¬åœ°) | Milvus, Qdrant |
| **å›¾æ•°æ®åº“** | Neo4j (å¯é€‰) | ArangoDB, JanusGraph |
| **OCR å¼•æ“** | PaddleOCR | Tesseract, EasyOCR |

---

## é™„å½•

### A. é…ç½®æ–‡ä»¶å®Œæ•´è§£è¯»

è¯¦è§ `config_local.yaml`ï¼š
- OCR é…ç½®ï¼šPaddleOCR å‚æ•°
- æ–‡æœ¬åˆ‡åˆ†é…ç½®ï¼šToken-based chunking å‚æ•°
- é—®é¢˜ç”Ÿæˆé…ç½®ï¼šDeepSeek-R1 å‚æ•°ã€çŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡é…ç½®
- RAG é…ç½®ï¼šLightRAG å‚æ•°ã€æ£€ç´¢ç­–ç•¥é…ç½®
- æç¤ºè¯é…ç½®ï¼šSystem promptã€Human promptã€Answer system prompt

### B. å¸¸è§é—®é¢˜ (FAQ)

**Q1: ä¸ºä»€ä¹ˆé€‰æ‹© DeepSeek-R1 è€Œä¸æ˜¯ GPT-4ï¼Ÿ**
A: DeepSeek-R1 æ˜¯å®Œå…¨æœ¬åœ°åŒ–çš„æ¨¡å‹ï¼Œæ•°æ®éšç§å®‰å…¨ï¼Œä¸”æˆæœ¬æ›´ä½ã€‚

**Q2: LightRAG ä¸ LangChain æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**
A: LightRAG æ›´è½»é‡çº§ï¼Œè‡ªåŠ¨æ„å»ºçŸ¥è¯†å›¾è°±ï¼Œè€Œ LangChain æ›´çµæ´»ä½†éœ€è¦æ‰‹åŠ¨é…ç½®ã€‚

**Q3: ä¸ºä»€ä¹ˆä½¿ç”¨ Token-based chunkingï¼Ÿ**
A: Token-based chunking ä¸ LLM token é™åˆ¶å¯¹é½ï¼Œé¿å…å¥å­æˆªæ–­ï¼Œä¸”ä¸ LightRAG ä¿æŒä¸€è‡´ã€‚

**Q4: å¦‚ä½•æå‡é—®é¢˜ç”Ÿæˆè´¨é‡ï¼Ÿ**
A: å¢åŠ çŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡ã€ä½¿ç”¨ Few-shot ç¤ºä¾‹ã€å¯ç”¨é—®é¢˜å»é‡ä¸è´¨é‡è¿‡æ»¤ã€‚

**Q5: å¦‚ä½•æå‡ç­”æ¡ˆç”Ÿæˆè´¨é‡ï¼Ÿ**
A: å¤šè·¯æ£€ç´¢èåˆã€å¹»è§‰æ£€æµ‹ã€ç­”æ¡ˆåå¤„ç†ã€å¤šæ¬¡é‡è¯•ã€‚

### C. å‚è€ƒèµ„æ–™

1. **LightRAG å®˜æ–¹æ–‡æ¡£**: https://github.com/HKUDS/LightRAG
2. **DeepSeek-R1 æŠ€æœ¯æŠ¥å‘Š**: https://github.com/deepseek-ai/DeepSeek-R1
3. **PaddleOCR æ–‡æ¡£**: https://github.com/PaddlePaddle/PaddleOCR
4. **RAGAs è¯„ä¼°æ¡†æ¶**: https://github.com/explodinggradients/ragas
5. **BGE-M3 è®ºæ–‡**: https://arxiv.org/abs/2402.03216

---

**æ–‡æ¡£ç»“æŸ**

> æœ¬æ–‡æ¡£ç”± AI åŠ©æ‰‹ç”Ÿæˆï¼ŒåŸºäºé¡¹ç›®ä»£ç å’Œé…ç½®æ–‡ä»¶åˆ†æè€Œæˆã€‚  
> å¦‚æœ‰ç–‘é—®æˆ–å»ºè®®ï¼Œè¯·è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚

